import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
import os
import random
import json
# import cv2 # Kh√¥ng th·∫•y cv2 ƒë∆∞·ª£c s·ª≠ d·ª•ng tr·ª±c ti·∫øp, c√≥ th·ªÉ b·ªè n·∫øu kh√¥ng c·∫ßn
# import numpy as np # T∆∞∆°ng t·ª±, c√≥ th·ªÉ b·ªè n·∫øu kh√¥ng c·∫ßn

# Gi·∫£ s·ª≠ c√°c file utils.py c·ªßa grad_cam n·∫±m trong th∆∞ m·ª•c MedMamba/grad_cam/
# v√† app_streamlit_demo.py n·∫±m trong MedMamba/
try:
    from grad_cam.utils import GradCAM, show_cam_on_image
except ImportError:
    st.error("Kh√¥ng th·ªÉ import GradCAM ho·∫∑c show_cam_on_image t·ª´ grad_cam.utils. ƒê·∫£m b·∫£o th∆∞ m·ª•c grad_cam v√† file utils.py ·ªü ƒë√∫ng v·ªã tr√≠ (v√≠ d·ª•: MedMamba/grad_cam/utils.py).")
    st.stop()


# Gi·∫£ s·ª≠ MedMamba.py n·∫±m c√πng c·∫•p ho·∫∑c trong PYTHONPATH
try:
    from MedMamba import VSSM as medmamba
except ImportError:
    st.error("Kh√¥ng th·ªÉ import MedMamba. H√£y ƒë·∫£m b·∫£o MedMamba.py ·ªü ƒë√∫ng v·ªã tr√≠.")
    st.stop()

# --- L·ªõp v√† H√†m cho Grad-CAM ---
class MedMambaReshapeTransform:
    def __call__(self, x: torch.Tensor) -> torch.Tensor:
        if x.ndim == 4:
            if x.shape[1] == x.shape[2] and x.shape[1] > x.shape[3]: # (B, H, W, C)
                return x.permute(0, 3, 1, 2) # Chuy·ªÉn th√†nh (B, C, H, W)
        return x

def generate_gradcam_image(model, device, pil_image, target_category_for_gradcam, class_indices,
                           img_size=224):
    try:
        if not (hasattr(model, 'layers') and model.layers and
                len(model.layers) > 0 and hasattr(model.layers[-1], 'blocks') and
                model.layers[-1].blocks and len(model.layers[-1].blocks) > 0 and
                hasattr(model.layers[-1].blocks[-1], 'conv33conv33conv11') and
                model.layers[-1].blocks[-1].conv33conv33conv11 and
                len(model.layers[-1].blocks[-1].conv33conv33conv11) >= 2):
            st.error("C·∫•u tr√∫c model kh√¥ng ph√π h·ª£p ho·∫∑c kh√¥ng ƒë·ªß s√¢u ƒë·ªÉ l·∫•y target_layer cho Grad-CAM (v√≠ d·ª•: model.layers[-1].blocks[-1].conv33conv33conv11[-2]).")
            return None, None
        
        target_layer = model.layers[-1].blocks[-1].conv33conv33conv11[-2]
        target_layers = [target_layer]

        data_transform_gradcam = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        img_tensor_transformed = data_transform_gradcam(pil_image.convert('RGB'))
        input_tensor = torch.unsqueeze(img_tensor_transformed, dim=0).to(device)

        img_for_display_unnormalized = img_tensor_transformed.cpu().clone()
        mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)
        std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)
        img_for_display_unnormalized = img_for_display_unnormalized * std + mean
        img_for_display_unnormalized = torch.clamp(img_for_display_unnormalized, 0, 1)
        img_for_display = img_for_display_unnormalized.permute(1, 2, 0).numpy()

        reshape_transform = MedMambaReshapeTransform()
        cam_algorithm = GradCAM(model=model,
                                target_layers=target_layers,
                                use_cuda=torch.cuda.is_available(),
                                reshape_transform=reshape_transform)

        model.eval()
        grayscale_cam = cam_algorithm(input_tensor=input_tensor, target_category=target_category_for_gradcam)
        
        if grayscale_cam is None:
            st.error("Grad-CAM kh√¥ng t·∫°o ra output. ƒêi·ªÅu n√†y c√≥ th·ªÉ x·∫£y ra n·∫øu target_layer kh√¥ng ph√π h·ª£p ho·∫∑c gradient l√† zero.")
            return None, None
        grayscale_cam = grayscale_cam[0, :]

        cam_image_result = show_cam_on_image(img_for_display, grayscale_cam, use_rgb=True)

        return img_for_display, cam_image_result

    except AttributeError as e:
        st.error(f"L·ªói thu·ªôc t√≠nh khi t·∫°o Grad-CAM: {e}. ƒêi·ªÅu n√†y c√≥ th·ªÉ do c·∫•u tr√∫c model kh√¥ng nh∆∞ mong ƒë·ª£i ho·∫∑c target_layer kh√¥ng t·ªìn t·∫°i.")
        return None, None
    except Exception as e:
        st.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫°o Grad-CAM: {e}")
        return None, None

# --- C·∫•u h√¨nh v√† H√†m h·ªó tr·ª£ ---
def get_transform(img_size=224):
    return transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

@st.cache_resource
def load_medmamba_model(checkpoint_path, num_classes):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
        
        actual_num_classes = checkpoint.get('num_classes')
        if actual_num_classes is None:
            st.warning(f"Checkpoint kh√¥ng ch·ª©a 'num_classes'. S·ª≠ d·ª•ng gi√° tr·ªã ƒë·∫ßu v√†o: {num_classes}.")
        elif actual_num_classes != num_classes:
            st.warning(f"S·ªë l·ªõp trong checkpoint ({actual_num_classes}) kh√°c v·ªõi s·ªë l·ªõp nh·∫≠p v√†o ({num_classes}). S·ª≠ d·ª•ng gi√° tr·ªã t·ª´ checkpoint: {actual_num_classes}.")
            num_classes = actual_num_classes
            
        model = medmamba(num_classes=num_classes)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        model.to(device)
        
        class_indices_from_ckpt = checkpoint.get('class_indices')
        if class_indices_from_ckpt and isinstance(class_indices_from_ckpt, dict):
            if all(isinstance(k, int) for k in class_indices_from_ckpt.keys()):
                 class_indices_from_ckpt = {str(k): v for k,v in class_indices_from_ckpt.items()}
        
        st.success(f"M√¥ h√¨nh ƒë∆∞·ª£c n·∫°p th√†nh c√¥ng t·ª´ '{os.path.basename(checkpoint_path)}' tr√™n {device}.")
        return model, device, class_indices_from_ckpt, num_classes
    except FileNotFoundError:
        st.error(f"Kh√¥ng t√¨m th·∫•y t·ªáp checkpoint t·∫°i: {checkpoint_path}")
    except KeyError as e:
        st.error(f"L·ªói KeyError khi n·∫°p checkpoint (c√≥ th·ªÉ thi·∫øu 'model_state_dict' ho·∫∑c 'num_classes'): {e}")
    except Exception as e:
        st.error(f"L·ªói khi n·∫°p m√¥ h√¨nh: {e}")
    return None, None, None, num_classes


@st.cache_data
def load_class_indices_from_file(class_indices_path):
    if class_indices_path and os.path.exists(class_indices_path):
        try:
            with open(class_indices_path, 'r') as f:
                class_indices = json.load(f)
            if isinstance(class_indices, dict) and any(isinstance(k, int) for k in class_indices.keys()):
                 class_indices = {str(k): v for k,v in class_indices.items()}
            st.info(f"ƒê√£ n·∫°p class_indices t·ª´ t·ªáp: {class_indices_path}")
            return class_indices
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ n·∫°p class_indices t·ª´ '{class_indices_path}': {e}")
    return None

def predict(model, device, image_pil, transform, class_indices):
    img_tensor = transform(image_pil.convert('RGB'))
    input_tensor = torch.unsqueeze(img_tensor, dim=0).to(device)

    with torch.no_grad():
        output_logits = model(input_tensor)
        probabilities = torch.softmax(output_logits, dim=1)
        predicted_prob_tensor, predicted_idx_tensor = torch.max(probabilities, dim=1)
        predicted_idx = predicted_idx_tensor.item()
        predicted_confidence = predicted_prob_tensor.item()

    predicted_class_name_display = str(predicted_idx) # Hi·ªÉn th·ªã index n·∫øu kh√¥ng c√≥ t√™n
    if class_indices and str(predicted_idx) in class_indices:
        predicted_class_name_display = class_indices[str(predicted_idx)]
    elif class_indices: # C√≥ class_indices nh∆∞ng index d·ª± ƒëo√°n kh√¥ng c√≥ trong ƒë√≥
        predicted_class_name_display = f"L·ªõp kh√¥ng x√°c ƒë·ªãnh (Index: {predicted_idx})"
    
    return predicted_class_name_display, predicted_confidence, predicted_idx

# --- Giao di·ªán Streamlit ---
def main_app():
    st.set_page_config(page_title="Demo MedMamba", layout="wide")
    st.title("üêç Demo Ph√¢n Lo·∫°i ·∫¢nh Y T·∫ø v·ªõi MedMamba")

    st.sidebar.header("‚öôÔ∏è C·∫•u H√¨nh M√¥ H√¨nh")
    
    if 'checkpoint_path_input' not in st.session_state:
        st.session_state.checkpoint_path_input = "YOUR_MODEL_CHECKPOINT.pth"
    if 'class_indices_path_input' not in st.session_state:
        st.session_state.class_indices_path_input = "class_indices.json"
    if 'num_classes_input' not in st.session_state:
        st.session_state.num_classes_input = 3 # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
    
    st.session_state.checkpoint_path_input = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Checkpoint (.pth)", 
        value=st.session_state.checkpoint_path_input,
        help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn t·ªáp checkpoint c·ªßa m√¥ h√¨nh MedMamba."
    )

    if 'model' not in st.session_state: # Kh·ªüi t·∫°o c√°c session_state li√™n quan ƒë·∫øn model
        st.session_state.model = None
        st.session_state.device = None
        st.session_state.class_indices = None # S·∫Ω ƒë∆∞·ª£c n·∫°p t·ª´ checkpoint ho·∫∑c file
        st.session_state.num_classes_loaded = st.session_state.num_classes_input
        st.session_state.model_loaded_path = ""
        st.session_state.last_prediction_info = None
        st.session_state.image_to_display_caption = ""
        st.session_state.image_to_display_pil = None

    if st.sidebar.button("N·∫°p M√¥ H√¨nh", key="load_model_button"):
        st.session_state.model = None 
        st.session_state.last_prediction_info = None 
        st.session_state.image_to_display_pil = None # Reset ·∫£nh khi n·∫°p l·∫°i model
        if st.session_state.checkpoint_path_input:
            model, device, class_indices_from_ckpt, num_classes_final = load_medmamba_model(
                st.session_state.checkpoint_path_input, 
                st.session_state.num_classes_input # Truy·ªÅn num_classes_input l√†m fallback
            )
            
            if model and device:
                st.session_state.model = model
                st.session_state.device = device
                st.session_state.num_classes_loaded = num_classes_final
                st.session_state.model_loaded_path = st.session_state.checkpoint_path_input

                # ∆Øu ti√™n class_indices t·ª´ file n·∫øu c√≥, sau ƒë√≥ t·ª´ checkpoint
                class_indices_from_file = load_class_indices_from_file(st.session_state.class_indices_path_input)
                if class_indices_from_file:
                    st.session_state.class_indices = class_indices_from_file
                elif class_indices_from_ckpt:
                    st.session_state.class_indices = class_indices_from_ckpt
                    st.sidebar.info("ƒê√£ s·ª≠ d·ª•ng class_indices t·ª´ checkpoint.")
                else:
                    st.session_state.class_indices = None
                    st.sidebar.warning("Kh√¥ng t√¨m th·∫•y class_indices (t·ª´ file ho·∫∑c checkpoint). D·ª± ƒëo√°n s·∫Ω ch·ªâ hi·ªÉn th·ªã index c·ªßa l·ªõp.")
            # else: L·ªói ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã trong load_medmamba_model
        else:
            st.sidebar.error("Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn checkpoint.")

    if st.session_state.model is None:
        st.warning("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c n·∫°p. Vui l√≤ng c·∫•u h√¨nh v√† nh·∫•n 'N·∫°p M√¥ H√¨nh' trong thanh sidebar.")
        st.stop()

    st.success(f"M√¥ h√¨nh **{os.path.basename(st.session_state.model_loaded_path)}** ƒë√£ ƒë∆∞·ª£c n·∫°p v√† s·∫µn s√†ng!")
    st.info(f"S·ªë l·ªõp c·ªßa m√¥ h√¨nh: **{st.session_state.num_classes_loaded}**")
    if st.session_state.class_indices:
        st.write("C√°c l·ªõp ƒë∆∞·ª£c ph√°t hi·ªán (t·ª´ class_indices):")
        st.json(st.session_state.class_indices, expanded=False)
    
    img_transform = get_transform()

    st.markdown("---")
    st.header("üî¨ Ch·ªçn ·∫¢nh & Xem K·∫øt Qu·∫£ Ph√¢n T√≠ch")
    
    prediction_mode = st.radio(
        "Ch·ªçn ngu·ªìn ·∫£nh:",
        ("T·∫£i ·∫¢nh L√™n", "·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c"),
        key="prediction_mode_radio",
        horizontal=True
    )

    # X·ª≠ l√Ω vi·ªác ch·ªçn ·∫£nh v√† n√∫t b·∫•m
    if prediction_mode == "T·∫£i ·∫¢nh L√™n":
        uploaded_file = st.file_uploader(
            "Ch·ªçn m·ªôt h√¨nh ·∫£nh...", 
            type=["png", "jpg", "jpeg", "bmp"],
            key="file_uploader",
            on_change=lambda: st.session_state.update(last_prediction_info=None, image_to_display_pil=None)
        )
        if uploaded_file is not None:
            try:
                st.session_state.image_to_display_pil = Image.open(uploaded_file).convert('RGB')
                st.session_state.image_to_display_caption = f"·∫¢nh ƒê√£ T·∫£i L√™n: {uploaded_file.name}"
            except Exception as e:
                st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh t·∫£i l√™n: {e}")
                st.session_state.image_to_display_pil = None

    elif prediction_mode == "·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c":
        if 'test_dir_input' not in st.session_state:
            st.session_state.test_dir_input = "PATH_TO_YOUR_TEST_IMAGE_FOLDER"

        st.session_state.test_dir_input = st.text_input(
            "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Th∆∞ M·ª•c ·∫¢nh Test (c√≥ c·∫•u tr√∫c l·ªõp con)", 
            value=st.session_state.test_dir_input,
            help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c ·∫£nh. T√™n th∆∞ m·ª•c con tr·ª±c ti·∫øp ch·ª©a ·∫£nh s·∫Ω ƒë∆∞·ª£c d√πng l√†m t√™n l·ªõp th·ª±c t·∫ø."
        )

        if st.button("L·∫•y ·∫¢nh Ng·∫´u Nhi√™n, D·ª± ƒêo√°n & Hi·ªán Grad-CAM", key="random_predict_gradcam_button"):
            st.session_state.last_prediction_info = None 
            st.session_state.image_to_display_pil = None
            if not os.path.isdir(st.session_state.test_dir_input):
                st.error(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {st.session_state.test_dir_input}")
            else:
                image_files = []
                for root, _, files in os.walk(st.session_state.test_dir_input):
                    for file in files:
                        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                            # ƒê·∫£m b·∫£o ch·ªâ l·∫•y ·∫£nh t·ª´ th∆∞ m·ª•c con tr·ª±c ti·∫øp (kh√¥ng ph·∫£i root c·ªßa test_dir)
                            if os.path.dirname(root) == st.session_state.test_dir_input or os.path.dirname(root) == st.session_state.test_dir_input.rstrip('/\\'):
                                image_files.append(os.path.join(root, file))
                
                if not image_files:
                    st.warning(f"Kh√¥ng t√¨m th·∫•y t·ªáp ·∫£nh n√†o trong c√°c th∆∞ m·ª•c con tr·ª±c ti·∫øp c·ªßa: {st.session_state.test_dir_input}")
                else:
                    random_image_path = random.choice(image_files)
                    try:
                        random_pil_image = Image.open(random_image_path).convert('RGB')
                        st.session_state.image_to_display_pil = random_pil_image
                        st.session_state.image_to_display_caption = f"·∫¢nh Ng·∫´u Nhi√™n: {os.path.basename(random_image_path)} (T·ª´: {os.path.basename(os.path.dirname(random_image_path))})"
                        
                        # Tr√≠ch xu·∫•t nh√£n th·ª±c t·∫ø t·ª´ t√™n th∆∞ m·ª•c
                        ground_truth_class_name_from_folder = os.path.basename(os.path.dirname(random_image_path))
                        ground_truth_class_idx = None
                        if st.session_state.class_indices:
                            for idx_str, name_in_indices in st.session_state.class_indices.items():
                                if name_in_indices == ground_truth_class_name_from_folder:
                                    try:
                                        ground_truth_class_idx = int(idx_str)
                                        break
                                    except ValueError: pass 
                            if ground_truth_class_idx is None:
                                st.info(f"T√™n l·ªõp t·ª´ th∆∞ m·ª•c '{ground_truth_class_name_from_folder}' kh√¥ng kh·ªõp v·ªõi class_indices. Kh√¥ng th·ªÉ t·ª± ƒë·ªông x√°c ƒë·ªãnh l·ªõp th·ª±c t·∫ø.")
                        else:
                            st.info("Kh√¥ng c√≥ class_indices, kh√¥ng th·ªÉ t·ª± ƒë·ªông x√°c ƒë·ªãnh l·ªõp th·ª±c t·∫ø t·ª´ t√™n th∆∞ m·ª•c.")

                        with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                            pred_name, pred_conf, pred_idx = predict(
                                st.session_state.model, st.session_state.device,
                                random_pil_image, img_transform, st.session_state.class_indices
                            )
                        st.session_state.last_prediction_info = {
                            "image_pil": random_pil_image,
                            "image_caption": st.session_state.image_to_display_caption,
                            "predicted_class_display_name": pred_name,
                            "predicted_confidence": pred_conf,
                            "predicted_idx": pred_idx,
                            "ground_truth_class_name_from_folder": ground_truth_class_name_from_folder,
                            "ground_truth_class_idx": ground_truth_class_idx # C√≥ th·ªÉ l√† None
                        }
                    except Exception as e:
                        st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh {random_image_path}: {e}")
                        st.session_state.image_to_display_pil = None
    
    # N√∫t "Th·ª±c Hi·ªán D·ª± ƒêo√°n" cho ·∫£nh t·∫£i l√™n
    if prediction_mode == "T·∫£i ·∫¢nh L√™n" and st.session_state.image_to_display_pil:
        if st.button("Th·ª±c Hi·ªán D·ª± ƒêo√°n & Hi·ªán Grad-CAM", key="upload_predict_gradcam_button"):
            st.session_state.last_prediction_info = None # Reset
            with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                pred_name, pred_conf, pred_idx = predict(
                    st.session_state.model, st.session_state.device,
                    st.session_state.image_to_display_pil, img_transform, st.session_state.class_indices
                )
            st.session_state.last_prediction_info = {
                "image_pil": st.session_state.image_to_display_pil,
                "image_caption": st.session_state.image_to_display_caption,
                "predicted_class_display_name": pred_name,
                "predicted_confidence": pred_conf,
                "predicted_idx": pred_idx,
                "ground_truth_class_name_from_folder": None, # Kh√¥ng √°p d·ª•ng
                "ground_truth_class_idx": None # Kh√¥ng √°p d·ª•ng
            }

    # Hi·ªÉn th·ªã ·∫£nh g·ªëc (n·∫øu c√≥)
    if st.session_state.get('image_to_display_pil') is not None:
        st.image(st.session_state.image_to_display_pil, caption=st.session_state.get('image_to_display_caption',"·∫¢nh ƒë√£ ch·ªçn"), width=300)
    elif prediction_mode == "T·∫£i ·∫¢nh L√™n": # Ch·ªâ hi·ªÉn th·ªã th√¥ng b√°o n√†y n·∫øu ch∆∞a c√≥ ·∫£nh v√† ƒëang ·ªü mode T·∫£i L√™n
        st.info("Vui l√≤ng t·∫£i ·∫£nh l√™n v√† nh·∫•n n√∫t 'Th·ª±c Hi·ªán D·ª± ƒêo√°n & Hi·ªán Grad-CAM'.")
    
    # --- Ph·∫ßn hi·ªÉn th·ªã k·∫øt qu·∫£ v√† Grad-CAM ---
    last_prediction_info = st.session_state.get('last_prediction_info', None)

    if last_prediction_info and last_prediction_info.get("image_pil") is not None:
        st.markdown("---")

        # --- L·∫§Y INPUT V√Ä X√ÅC ƒê·ªäNH L·ªöP M·ª§C TI√äU CHO GRAD-CAM ---
        pil_image_for_gradcam = last_prediction_info["image_pil"]
        predicted_idx = last_prediction_info["predicted_idx"]
        predicted_class_display_name = last_prediction_info["predicted_class_display_name"]
        
        grad_cam_target_source_options = {}
        has_valid_ground_truth = False

        # 1. T√πy ch·ªçn: L·ªõp th·ª±c t·∫ø t·ª´ Dataset (n·∫øu c√≥ v√† h·ª£p l·ªá)
        gt_idx_from_data = last_prediction_info.get("ground_truth_class_idx")
        if gt_idx_from_data is not None and (0 <= gt_idx_from_data < st.session_state.num_classes_loaded):
            gt_name_display = st.session_state.class_indices.get(str(gt_idx_from_data), last_prediction_info.get("ground_truth_class_name_from_folder", f"Index {gt_idx_from_data}"))
            grad_cam_target_source_options["ground_truth"] = f"L·ªõp th·ª±c t·∫ø t·ª´ Dataset: '{gt_name_display}' (Index: {gt_idx_from_data})"
            has_valid_ground_truth = True
        
        # 2. T√πy ch·ªçn: L·ªõp d·ª± ƒëo√°n b·ªüi m√¥ h√¨nh
        grad_cam_target_source_options["predicted"] = f"L·ªõp d·ª± ƒëo√°n: '{predicted_class_display_name}' (Index: {predicted_idx})"
        
        # 3. T√πy ch·ªçn: Nh·∫≠p th·ªß c√¥ng
        grad_cam_target_source_options["manual"] = "Nh·∫≠p th·ªß c√¥ng Index l·ªõp"

        # X√°c ƒë·ªãnh l·ª±a ch·ªçn m·∫∑c ƒë·ªãnh v√† qu·∫£n l√Ω state cho selectbox
        grad_cam_source_key = f"grad_cam_source_for_{id(pil_image_for_gradcam)}"
        default_source_key = "predicted"
        if has_valid_ground_truth: # ∆Øu ti√™n ground truth n·∫øu c√≥
            default_source_key = "ground_truth"
        
        current_source_selection = st.session_state.get(grad_cam_source_key, default_source_key)
        # ƒê·∫£m b·∫£o l·ª±a ch·ªçn hi·ªán t·∫°i v·∫´n h·ª£p l·ªá (v√≠ d·ª•: ground_truth c√≥ th·ªÉ kh√¥ng c√≤n n·∫øu ƒë·ªïi ·∫£nh)
        if current_source_selection == "ground_truth" and not has_valid_ground_truth:
            current_source_selection = default_source_key
        if current_source_selection not in grad_cam_target_source_options:
            current_source_selection = default_source_key
            
        options_keys_list = list(grad_cam_target_source_options.keys())
        try:
            current_selection_index = options_keys_list.index(current_source_selection)
        except ValueError:
             current_selection_index = options_keys_list.index(default_source_key)


        selected_grad_cam_source = st.selectbox(
            "üéØ **Ch·ªçn ngu·ªìn cho L·ªõp M·ª•c Ti√™u Grad-CAM:**",
            options=options_keys_list,
            format_func=lambda k: grad_cam_target_source_options[k],
            key=grad_cam_source_key, # Streamlit t·ª± qu·∫£n l√Ω state qua key
            index=current_selection_index
        )
        
        target_category_input_str = "" # Cho tr∆∞·ªùng h·ª£p manual
        if selected_grad_cam_source == "manual":
            manual_input_key = f"manual_grad_cam_target_for_{id(pil_image_for_gradcam)}"
            current_manual_val = st.session_state.get(manual_input_key, str(predicted_idx))
            target_category_input_str = st.text_input(
                label="Nh·∫≠p Index L·ªõp M·ª•c Ti√™u th·ªß c√¥ng:",
                value=current_manual_val, # Gi·ªØ l·∫°i gi√° tr·ªã ƒë√£ nh·∫≠p tr∆∞·ªõc ƒë√≥ cho ·∫£nh n√†y
                key=manual_input_key # Streamlit t·ª± qu·∫£n l√Ω state qua key
            )

        # X√°c ƒë·ªãnh target_category_for_gradcam_final d·ª±a tr√™n l·ª±a ch·ªçn
        target_category_for_gradcam_final = predicted_idx # M·∫∑c ƒë·ªãnh fallback
        error_parsing_manual_input = False

        if selected_grad_cam_source == "ground_truth" and has_valid_ground_truth:
            target_category_for_gradcam_final = gt_idx_from_data
        elif selected_grad_cam_source == "predicted":
            target_category_for_gradcam_final = predicted_idx
        elif selected_grad_cam_source == "manual":
            if target_category_input_str.strip():
                try:
                    target_category_for_gradcam_final = int(target_category_input_str)
                except ValueError:
                    error_parsing_manual_input = True
                    # N·∫øu l·ªói, s·∫Ω fallback v·ªÅ predicted_idx (ƒë√£ g√°n ·ªü tr√™n)
            # else: input r·ªóng, fallback v·ªÅ predicted_idx (ƒë√£ g√°n ·ªü tr√™n)
        
        # L·∫•y t√™n hi·ªÉn th·ªã cho l·ªõp m·ª•c ti√™u cu·ªëi c√πng
        final_target_display_name = str(target_category_for_gradcam_final)
        if st.session_state.class_indices and str(target_category_for_gradcam_final) in st.session_state.class_indices:
            final_target_display_name = st.session_state.class_indices[str(target_category_for_gradcam_final)]
        elif not st.session_state.class_indices:
            final_target_display_name = f"Index: {target_category_for_gradcam_final}"
        else: # C√≥ class_indices nh∆∞ng index kh√¥ng c√≥ t√™n
             final_target_display_name = f"(T√™n kh√¥ng r√µ cho Index: {target_category_for_gradcam_final})"


        # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN V√Ä L·ªöP M·ª§C TI√äU ƒê√É CH·ªåN ---
        st.subheader("K·∫øt Qu·∫£ Ph√¢n T√≠ch ·∫¢nh:")
        st.markdown(f"**L·ªõp M·ª•c Ti√™u (cho Grad-CAM):** `{final_target_display_name}` (Index: {target_category_for_gradcam_final})")
        st.caption(f"Ngu·ªìn l·ª±a ch·ªçn: {grad_cam_target_source_options[selected_grad_cam_source]}")
        
        st.markdown(f"**L·ªõp D·ª± ƒêo√°n (t·ª´ m√¥ h√¨nh):** `{last_prediction_info['predicted_class_display_name']}` (Index: {last_prediction_info['predicted_idx']})")
        st.markdown(f"**ƒê·ªô Tin C·∫≠y (c·ªßa l·ªõp d·ª± ƒëo√°n):** `{last_prediction_info['predicted_confidence']:.4f}`")

        if error_parsing_manual_input:
            st.warning(f"Gi√° tr·ªã '{target_category_input_str}' nh·∫≠p th·ªß c√¥ng kh√¥ng h·ª£p l·ªá. ƒêang s·ª≠ d·ª•ng l·ªõp m·ª•c ti√™u l√† l·ªõp d·ª± ƒëo√°n (Index: {predicted_idx}).")

        # --- GRAD-CAM VISUALIZATION ---
        st.subheader("üî• Grad-CAM Visualization")
        
        num_classes_loaded = st.session_state.num_classes_loaded
        if not (0 <= target_category_for_gradcam_final < num_classes_loaded):
            st.error(f"Target Category Index ({target_category_for_gradcam_final}) n·∫±m ngo√†i kho·∫£ng h·ª£p l·ªá [0, {num_classes_loaded-1}]. Vui l√≤ng ch·ªçn m·ªôt index h·ª£p l·ªá.")
        else:
            with st.spinner("ƒêang t·∫°o Grad-CAM..."):
                original_img_display, cam_image = generate_gradcam_image(
                    st.session_state.model, st.session_state.device,
                    pil_image_for_gradcam, 
                    target_category_for_gradcam_final, 
                    st.session_state.class_indices,
                    img_size=224
                )

            if original_img_display is not None and cam_image is not None:
                col_img1, col_img2 = st.columns(2)
                with col_img1:
                    st.image(original_img_display, caption=last_prediction_info.get("image_caption", "·∫¢nh ƒë√£ x·ª≠ l√Ω"), use_container_width=True)
                with col_img2:
                    st.image(cam_image, caption=f"Grad-CAM cho l·ªõp: {final_target_display_name}", use_container_width=True)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("ƒê∆∞·ª£c h·ªó tr·ª£ b·ªüi ƒê·ªëi t√°c L·∫≠p tr√¨nh Gemini")

if __name__ == '__main__':
    main_app()