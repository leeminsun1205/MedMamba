import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
import os
import random
import json

from grad_cam.utils import GradCAM, show_cam_on_image
from MedMamba import VSSM as medmamba


# --- L·ªõp v√† H√†m cho Grad-CAM ---
class MedMambaReshapeTransform:
    def __call__(self, x: torch.Tensor) -> torch.Tensor:
        if x.ndim == 4:
            if x.shape[1] == x.shape[2] and x.shape[1] > x.shape[3]: # (B, H, W, C)
                return x.permute(0, 3, 1, 2) # Chuy·ªÉn th√†nh (B, C, H, W)
        return x

def generate_gradcam_image(model, device, pil_image, target_category_for_gradcam, class_indices,
                           img_size=224): 
    # 1. X√°c ƒë·ªãnh target_layer cho MedMamba
    if not (hasattr(model, 'layers') and model.layers and
            len(model.layers) > 0 and hasattr(model.layers[-1], 'blocks') and
            model.layers[-1].blocks and len(model.layers[-1].blocks) > 0 and
            hasattr(model.layers[-1].blocks[-1], 'conv33conv33conv11') and
            model.layers[-1].blocks[-1].conv33conv33conv11 and
            len(model.layers[-1].blocks[-1].conv33conv33conv11) >= 2):
        st.error("C·∫•u tr√∫c model kh√¥ng ph√π h·ª£p ho·∫∑c kh√¥ng ƒë·ªß s√¢u ƒë·ªÉ l·∫•y target_layer cho Grad-CAM (v√≠ d·ª•: model.layers[-1].blocks[-1].conv33conv33conv11[-2]).")
        return None, None
    
    target_layer = model.layers[-1].blocks[-1].conv33conv33conv11[-2]
    target_layers = [target_layer]

    # 2. Chu·∫©n b·ªã ·∫£nh ƒë·∫ßu v√†o
    data_transform_gradcam = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    img_tensor_transformed = data_transform_gradcam(pil_image.convert('RGB'))
    input_tensor = torch.unsqueeze(img_tensor_transformed, dim=0).to(device)

    img_for_display_unnormalized = img_tensor_transformed.cpu().clone()
    mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)
    std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)
    img_for_display_unnormalized = img_for_display_unnormalized * std + mean
    img_for_display_unnormalized = torch.clamp(img_for_display_unnormalized, 0, 1)
    img_for_display = img_for_display_unnormalized.permute(1, 2, 0).numpy()

    # 3. Kh·ªüi t·∫°o GradCAM
    reshape_transform = MedMambaReshapeTransform()
    cam_algorithm = GradCAM(model=model,
                            target_layers=target_layers,
                            use_cuda=torch.cuda.is_available(),
                            reshape_transform=reshape_transform)

    # 4. T√≠nh to√°n Grad-CAM
    model.eval()
    grayscale_cam = cam_algorithm(input_tensor=input_tensor, target_category=target_category_for_gradcam)
    
    if grayscale_cam is None:
        st.error("Grad-CAM kh√¥ng t·∫°o ra output. ƒêi·ªÅu n√†y c√≥ th·ªÉ x·∫£y ra n·∫øu target_layer kh√¥ng ph√π h·ª£p ho·∫∑c gradient l√† zero.")
        return None, None
    grayscale_cam = grayscale_cam[0, :]

    # 5. Ph·ªß m√†u (kh√¥ng c√≤n l√†m m·ªãn)
    cam_image_result = show_cam_on_image(img_for_display, grayscale_cam, use_rgb=True)

    return img_for_display, cam_image_result


# --- C·∫•u h√¨nh v√† H√†m h·ªó tr·ª£ ---
def get_transform(img_size=224):
    return transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

@st.cache_resource
def load_medmamba_model(checkpoint_path, num_classes):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
        
        actual_num_classes = checkpoint.get('num_classes')
        if actual_num_classes is None:
            st.warning(f"Checkpoint kh√¥ng ch·ª©a 'num_classes'. S·ª≠ d·ª•ng gi√° tr·ªã ƒë·∫ßu v√†o: {num_classes}.")
        elif actual_num_classes != num_classes:
            st.warning(f"S·ªë l·ªõp trong checkpoint ({actual_num_classes}) kh√°c v·ªõi s·ªë l·ªõp nh·∫≠p v√†o ({num_classes}). S·ª≠ d·ª•ng gi√° tr·ªã t·ª´ checkpoint: {actual_num_classes}.")
            num_classes = actual_num_classes
            
        model = medmamba(num_classes=num_classes)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        model.to(device)
        
        class_indices_from_ckpt = checkpoint.get('class_indices')
        if class_indices_from_ckpt and isinstance(class_indices_from_ckpt, dict):
            if all(isinstance(k, int) for k in class_indices_from_ckpt.keys()):
                 class_indices_from_ckpt = {str(k): v for k,v in class_indices_from_ckpt.items()}
        
        st.success(f"M√¥ h√¨nh ƒë∆∞·ª£c n·∫°p th√†nh c√¥ng t·ª´ '{os.path.basename(checkpoint_path)}' tr√™n {device}.")
        return model, device, class_indices_from_ckpt, num_classes
    except FileNotFoundError:
        st.error(f"Kh√¥ng t√¨m th·∫•y t·ªáp checkpoint t·∫°i: {checkpoint_path}")
    except KeyError as e:
        st.error(f"L·ªói KeyError khi n·∫°p checkpoint (c√≥ th·ªÉ thi·∫øu 'model_state_dict' ho·∫∑c 'num_classes'): {e}")
    except Exception as e:
        st.error(f"L·ªói khi n·∫°p m√¥ h√¨nh: {e}")
    return None, None, None, num_classes


@st.cache_data
def load_class_indices_from_file(class_indices_path):
    if class_indices_path and os.path.exists(class_indices_path):
        try:
            with open(class_indices_path, 'r') as f:
                class_indices = json.load(f)
            if isinstance(class_indices, dict) and any(isinstance(k, int) for k in class_indices.keys()):
                 class_indices = {str(k): v for k,v in class_indices.items()}
            st.info(f"ƒê√£ n·∫°p class_indices t·ª´ t·ªáp: {class_indices_path}")
            return class_indices
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ n·∫°p class_indices t·ª´ '{class_indices_path}': {e}")
    return None

def predict(model, device, image_pil, transform, class_indices):
    img_tensor = transform(image_pil.convert('RGB'))
    input_tensor = torch.unsqueeze(img_tensor, dim=0).to(device)

    with torch.no_grad():
        output_logits = model(input_tensor)
        probabilities = torch.softmax(output_logits, dim=1)
        predicted_prob_tensor, predicted_idx_tensor = torch.max(probabilities, dim=1)
        predicted_idx = predicted_idx_tensor.item()
        predicted_confidence = predicted_prob_tensor.item()

    predicted_class_name = str(predicted_idx)
    if class_indices:
        predicted_class_name = class_indices.get(str(predicted_idx), f"L·ªõp kh√¥ng x√°c ƒë·ªãnh (Index: {predicted_idx})")
    
    return predicted_class_name, predicted_confidence, predicted_idx

# --- Giao di·ªán Streamlit ---
def main_app():
    st.set_page_config(page_title="Demo MedMamba", layout="wide")
    st.title("üêç Demo Ph√¢n Lo·∫°i ·∫¢nh Y T·∫ø v·ªõi MedMamba")

    st.sidebar.header("‚öôÔ∏è C·∫•u H√¨nh M√¥ H√¨nh")
    
    # S·ª≠ d·ª•ng session state ƒë·ªÉ l∆∞u ƒë∆∞·ªùng d·∫´n checkpoint v√† class_indices ƒë·ªÉ kh√¥ng b·ªã reset
    if 'checkpoint_path_input' not in st.session_state:
        st.session_state.checkpoint_path_input = "YOUR_MODEL_CHECKPOINT.pth"
    if 'class_indices_path_input' not in st.session_state:
        st.session_state.class_indices_path_input = "class_indices.json"
    if 'num_classes_input' not in st.session_state:
        st.session_state.num_classes_input = 3
    
    st.session_state.checkpoint_path_input = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Checkpoint (.pth)", 
        value=st.session_state.checkpoint_path_input,
        help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn t·ªáp checkpoint c·ªßa m√¥ h√¨nh MedMamba."
    )
    st.session_state.class_indices_path_input = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Class Indices (.json) (T√πy ch·ªçn)", 
        value=st.session_state.class_indices_path_input,
        help="T·ªáp JSON ch·ª©a √°nh x·∫° t·ª´ index sang t√™n l·ªõp."
    )
    st.session_state.num_classes_input = st.sidebar.number_input(
        "S·ªë L∆∞·ª£ng L·ªõp (n·∫øu kh√¥ng c√≥ trong checkpoint)", 
        min_value=1, value=st.session_state.num_classes_input, step=1,
        help="S·ªë l·ªõp ƒë·∫ßu ra c·ªßa m√¥ h√¨nh. S·∫Ω ƒë∆∞·ª£c ghi ƒë√® n·∫øu checkpoint ch·ª©a th√¥ng tin n√†y."
    )

    if 'model' not in st.session_state:
        st.session_state.model = None
        st.session_state.device = None
        st.session_state.class_indices = None
        st.session_state.num_classes_loaded = st.session_state.num_classes_input
        st.session_state.model_loaded_path = ""
        st.session_state.last_prediction_info = None

    if st.sidebar.button("N·∫°p M√¥ H√¨nh & Class Indices", key="load_model_button"):
        st.session_state.model = None 
        st.session_state.last_prediction_info = None 
        if st.session_state.checkpoint_path_input:
            model, device, class_indices_from_ckpt, num_classes_final = load_medmamba_model(
                st.session_state.checkpoint_path_input, 
                st.session_state.num_classes_input
            )
            
            if model and device:
                st.session_state.model = model
                st.session_state.device = device
                st.session_state.num_classes_loaded = num_classes_final
                st.session_state.model_loaded_path = st.session_state.checkpoint_path_input

                class_indices_from_file = load_class_indices_from_file(st.session_state.class_indices_path_input)
                if class_indices_from_file:
                    st.session_state.class_indices = class_indices_from_file
                elif class_indices_from_ckpt:
                    st.session_state.class_indices = class_indices_from_ckpt
                    st.sidebar.info("ƒê√£ s·ª≠ d·ª•ng class_indices t·ª´ checkpoint.")
                else:
                    st.session_state.class_indices = None
                    st.sidebar.warning("Kh√¥ng t√¨m th·∫•y class_indices. D·ª± ƒëo√°n s·∫Ω ch·ªâ hi·ªÉn th·ªã index c·ªßa l·ªõp.")
            else:
                st.session_state.model = None
                st.session_state.class_indices = None
        else:
            st.sidebar.error("Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn checkpoint.")

    if st.session_state.model is None:
        st.warning("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c n·∫°p. Vui l√≤ng c·∫•u h√¨nh v√† nh·∫•n 'N·∫°p M√¥ H√¨nh' trong thanh sidebar.")
        st.stop()

    st.success(f"M√¥ h√¨nh **{os.path.basename(st.session_state.model_loaded_path)}** ƒë√£ ƒë∆∞·ª£c n·∫°p v√† s·∫µn s√†ng!")
    st.info(f"S·ªë l·ªõp c·ªßa m√¥ h√¨nh: **{st.session_state.num_classes_loaded}**")
    if st.session_state.class_indices:
        st.write("C√°c l·ªõp ƒë∆∞·ª£c ph√°t hi·ªán:")
        st.json(st.session_state.class_indices, expanded=False)
    
    img_transform = get_transform()

    st.markdown("---")
    st.header("üî¨ Ch·∫ø ƒê·ªô D·ª± ƒêo√°n")
    prediction_mode = st.radio(
        "Ch·ªçn ch·∫ø ƒë·ªô d·ª± ƒëo√°n:",
        ("T·∫£i ·∫¢nh L√™n", "D·ª± ƒêo√°n ·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c"),
        key="prediction_mode_radio"
    )

    image_pil_for_prediction = None

    if prediction_mode == "T·∫£i ·∫¢nh L√™n":
        uploaded_file = st.file_uploader(
            "Ch·ªçn m·ªôt h√¨nh ·∫£nh...", 
            type=["png", "jpg", "jpeg", "bmp"],
            key="file_uploader"
        )
        if uploaded_file is not None:
            try:
                image_pil_for_prediction = Image.open(uploaded_file).convert('RGB')
                
                col1, col2 = st.columns([2,3])
                with col1:
                    st.image(image_pil_for_prediction, caption="·∫¢nh ƒê√£ T·∫£i L√™n", use_container_width=True)

                with col2:
                    if st.button("Th·ª±c Hi·ªán D·ª± ƒêo√°n", key="predict_uploaded_button"):
                        with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                            class_name, confidence, class_idx = predict(
                                st.session_state.model,
                                st.session_state.device,
                                image_pil_for_prediction,
                                img_transform,
                                st.session_state.class_indices
                            )
                        st.session_state.last_prediction_info = {
                            "image_pil": image_pil_for_prediction,
                            "class_name": class_name,
                            "confidence": confidence,
                            "predicted_idx": class_idx
                        }
                        st.subheader("K·∫øt Qu·∫£ D·ª± ƒêo√°n:")
                        st.markdown(f"**L·ªõp D·ª± ƒêo√°n:** `{class_name}` (Index: {class_idx})")
                        st.markdown(f"**ƒê·ªô Tin C·∫≠y:** `{confidence:.4f}`")
            except Exception as e:
                st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh t·∫£i l√™n: {e}")

    elif prediction_mode == "D·ª± ƒêo√°n ·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c":
        if 'test_dir_input' not in st.session_state:
            st.session_state.test_dir_input = "PATH_TO_YOUR_TEST_IMAGE_FOLDER"

        st.session_state.test_dir_input = st.text_input(
            "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Th∆∞ M·ª•c ·∫¢nh Test", 
            value=st.session_state.test_dir_input,
            help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c ·∫£nh ƒë·ªÉ ch·ªçn ng·∫´u nhi√™n."
        )

        if st.button("D·ª± ƒêo√°n ·∫¢nh Ng·∫´u Nhi√™n", key="predict_random_button"):
            if not os.path.isdir(st.session_state.test_dir_input):
                st.error(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {st.session_state.test_dir_input}")
            else:
                image_files = []
                for root, _, files in os.walk(st.session_state.test_dir_input):
                    for file in files:
                        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                            image_files.append(os.path.join(root, file))
                
                if not image_files:
                    st.warning(f"Kh√¥ng t√¨m th·∫•y t·ªáp ·∫£nh n√†o trong th∆∞ m·ª•c: {st.session_state.test_dir_input}")
                else:
                    random_image_path = random.choice(image_files)
                    try:
                        image_pil_for_prediction = Image.open(random_image_path).convert('RGB')
                        
                        col1, col2 = st.columns([2,3])
                        with col1:
                            st.image(image_pil_for_prediction, caption=f"·∫¢nh Ng·∫´u Nhi√™n: {os.path.basename(random_image_path)}", use_container_width=True)
                        
                        with col2:
                            with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                                class_name, confidence, class_idx = predict(
                                    st.session_state.model,
                                    st.session_state.device,
                                    image_pil_for_prediction,
                                    img_transform,
                                    st.session_state.class_indices
                                )
                            st.session_state.last_prediction_info = {
                                "image_pil": image_pil_for_prediction,
                                "class_name": class_name,
                                "confidence": confidence,
                                "predicted_idx": class_idx
                            }
                            st.subheader("K·∫øt Qu·∫£ D·ª± ƒêo√°n:")
                            st.markdown(f"**·∫¢nh ƒê∆∞·ª£c Ch·ªçn:** `{os.path.basename(random_image_path)}`")
                            st.markdown(f"**L·ªõp D·ª± ƒêo√°n:** `{class_name}` (Index: {class_idx})")
                            st.markdown(f"**ƒê·ªô Tin C·∫≠y:** `{confidence:.4f}`")
                    except Exception as e:
                        st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh {random_image_path}: {e}")
    
    # --- Ph·∫ßn Grad-CAM (Lu√¥n hi·ªÉn th·ªã n·∫øu c√≥ d·ª± ƒëo√°n) ---
    last_prediction_info = st.session_state.get('last_prediction_info', None)

    if last_prediction_info and last_prediction_info.get("image_pil") is not None:
        st.markdown("---")
        st.header("üî• Grad-CAM Visualization")

        pil_image_for_gradcam = last_prediction_info["image_pil"]
        predicted_idx_for_gradcam = last_prediction_info["predicted_idx"]
        predicted_class_name_display_gradcam = last_prediction_info["class_name"]

        # Cho ph√©p ng∆∞·ªùi d√πng t√πy ch·ªânh target category cho Grad-CAM
        if 'target_category_gradcam_input' not in st.session_state:
             st.session_state.target_category_gradcam_input = str(predicted_idx_for_gradcam)


        # S·ª≠ d·ª•ng key kh√°c ho·∫∑c reset n·∫øu predicted_idx_for_gradcam thay ƒë·ªïi ƒë·ªÉ c·∫≠p nh·∫≠t placeholder
        target_category_key = f"target_category_gradcam_input_for_{predicted_idx_for_gradcam}"

        target_category_input_gradcam = st.text_input(
            f"Index L·ªõp M·ª•c Ti√™u cho Grad-CAM (m·∫∑c ƒë·ªãnh: l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n - '{predicted_class_name_display_gradcam}' (Index: {predicted_idx_for_gradcam}))",
            key=target_category_key, # Key ƒë·ªông ƒë·ªÉ c√≥ th·ªÉ reset placeholder
            placeholder=str(predicted_idx_for_gradcam),
            value=st.session_state.get(target_category_key, str(predicted_idx_for_gradcam)) # Gi·ªØ gi√° tr·ªã n·∫øu c√≥
        )
        
        # C·∫≠p nh·∫≠t session state n·∫øu ng∆∞·ªùi d√πng thay ƒë·ªïi input
        st.session_state[target_category_key] = target_category_input_gradcam


        target_category_for_gradcam = predicted_idx_for_gradcam # M·∫∑c ƒë·ªãnh
        if target_category_input_gradcam.strip(): # Ch·ªâ x·ª≠ l√Ω n·∫øu input kh√¥ng r·ªóng
            try:
                target_category_for_gradcam = int(target_category_input_gradcam)
            except ValueError:
                st.warning(f"Gi√° tr·ªã '{target_category_input_gradcam}' kh√¥ng h·ª£p l·ªá cho Target Category. S·ª≠ d·ª•ng index l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n ({predicted_idx_for_gradcam}).")
                target_category_for_gradcam = predicted_idx_for_gradcam
        
        num_classes_loaded = st.session_state.num_classes_loaded
        if not (0 <= target_category_for_gradcam < num_classes_loaded):
            st.error(f"Target Category Index ({target_category_for_gradcam}) n·∫±m ngo√†i kho·∫£ng h·ª£p l·ªá [0, {num_classes_loaded-1}]. Vui l√≤ng ch·ªçn m·ªôt index h·ª£p l·ªá.")
        else:
            # Kh√¥ng c√≤n n√∫t "T·∫°o Grad-CAM", s·∫Ω t·ª± ƒë·ªông t·∫°o
            with st.spinner("ƒêang t·∫°o Grad-CAM... (C√≥ th·ªÉ m·∫•t m·ªôt ch√∫t th·ªùi gian)"):
                original_img_display, cam_image = generate_gradcam_image(
                    st.session_state.model,
                    st.session_state.device,
                    pil_image_for_gradcam,
                    target_category_for_gradcam,
                    st.session_state.class_indices,
                    img_size=224
                )

            if original_img_display is not None and cam_image is not None:
                st.subheader("K·∫øt Qu·∫£ Grad-CAM")
                
                target_gradcam_class_name_display = str(target_category_for_gradcam)
                if st.session_state.class_indices:
                    target_gradcam_class_name_display = st.session_state.class_indices.get(str(target_category_for_gradcam), str(target_category_for_gradcam))
                
                col_gradcam1, col_gradcam2 = st.columns(2)
                with col_gradcam1:
                    caption_original = f"·∫¢nh G·ªëc"
                    if last_prediction_info:
                        caption_original += f"\nD·ª± ƒëo√°n: {last_prediction_info['class_name']} ({last_prediction_info['confidence']:.2f})"
                    st.image(original_img_display, caption=caption_original, use_container_width=True)
                with col_gradcam2:
                    st.image(cam_image, caption=f"Grad-CAM cho l·ªõp: {target_gradcam_class_name_display}", use_container_width=True)
            # L·ªói ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω b√™n trong generate_gradcam_image
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("ƒê∆∞·ª£c h·ªó tr·ª£ b·ªüi ƒê·ªëi t√°c L·∫≠p tr√¨nh Gemini")

if __name__ == '__main__':
    main_app()