import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
import os
import random
import json
import cv2
import numpy as np

# Giáº£ sá»­ cÃ¡c file utils.py cá»§a grad_cam náº±m trong thÆ° má»¥c MedMamba/grad_cam/
# vÃ  app_streamlit_demo.py náº±m trong MedMamba/
try:
    from grad_cam.utils import GradCAM, show_cam_on_image #
except ImportError:
    st.error("KhÃ´ng thá»ƒ import GradCAM hoáº·c show_cam_on_image tá»« grad_cam.utils. Äáº£m báº£o thÆ° má»¥c grad_cam vÃ  file utils.py á»Ÿ Ä‘Ãºng vá»‹ trÃ­ (vÃ­ dá»¥: MedMamba/grad_cam/utils.py).") #
    st.stop()


# Giáº£ sá»­ MedMamba.py náº±m cÃ¹ng cáº¥p hoáº·c trong PYTHONPATH
try:
    from MedMamba import VSSM as medmamba #
except ImportError:
    st.error("KhÃ´ng thá»ƒ import MedMamba. HÃ£y Ä‘áº£m báº£o MedMamba.py á»Ÿ Ä‘Ãºng vá»‹ trÃ­.") #
    st.stop() #

# --- Lá»›p vÃ  HÃ m cho Grad-CAM ---
class MedMambaReshapeTransform: #
    def __call__(self, x: torch.Tensor) -> torch.Tensor: #
        if x.ndim == 4: #
            if x.shape[1] == x.shape[2] and x.shape[1] > x.shape[3]: # (B, H, W, C)
                return x.permute(0, 3, 1, 2) # Chuyá»ƒn thÃ nh (B, C, H, W)
        return x #

def generate_gradcam_image(model, device, pil_image, target_category_for_gradcam, class_indices,
                           img_size=224): #
    try:
        if not (hasattr(model, 'layers') and model.layers and
                len(model.layers) > 0 and hasattr(model.layers[-1], 'blocks') and
                model.layers[-1].blocks and len(model.layers[-1].blocks) > 0 and
                hasattr(model.layers[-1].blocks[-1], 'conv33conv33conv11') and
                model.layers[-1].blocks[-1].conv33conv33conv11 and
                len(model.layers[-1].blocks[-1].conv33conv33conv11) >= 2): #
            st.error("Cáº¥u trÃºc model khÃ´ng phÃ¹ há»£p hoáº·c khÃ´ng Ä‘á»§ sÃ¢u Ä‘á»ƒ láº¥y target_layer cho Grad-CAM (vÃ­ dá»¥: model.layers[-1].blocks[-1].conv33conv33conv11[-2]).") #
            return None, None
        
        target_layer = model.layers[-1].blocks[-1].conv33conv33conv11[-2] #
        target_layers = [target_layer] #

        data_transform_gradcam = transforms.Compose([ #
            transforms.Resize((img_size, img_size)), #
            transforms.ToTensor(), #
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #
        ])
        img_tensor_transformed = data_transform_gradcam(pil_image.convert('RGB')) #
        input_tensor = torch.unsqueeze(img_tensor_transformed, dim=0).to(device) #

        img_for_display_unnormalized = img_tensor_transformed.cpu().clone() #
        mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1) #
        std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1) #
        img_for_display_unnormalized = img_for_display_unnormalized * std + mean #
        img_for_display_unnormalized = torch.clamp(img_for_display_unnormalized, 0, 1) #
        img_for_display = img_for_display_unnormalized.permute(1, 2, 0).numpy() #

        reshape_transform = MedMambaReshapeTransform() #
        cam_algorithm = GradCAM(model=model, #
                                target_layers=target_layers, #
                                use_cuda=torch.cuda.is_available(), #
                                reshape_transform=reshape_transform) #

        model.eval() #
        grayscale_cam = cam_algorithm(input_tensor=input_tensor, target_category=target_category_for_gradcam) #
        
        if grayscale_cam is None: #
            st.error("Grad-CAM khÃ´ng táº¡o ra output. Äiá»u nÃ y cÃ³ thá»ƒ xáº£y ra náº¿u target_layer khÃ´ng phÃ¹ há»£p hoáº·c gradient lÃ  zero.") #
            return None, None
        grayscale_cam = grayscale_cam[0, :] #

        cam_image_result = show_cam_on_image(img_for_display, grayscale_cam, use_rgb=True) #

        return img_for_display, cam_image_result #

    except AttributeError as e: #
        st.error(f"Lá»—i thuá»™c tÃ­nh khi táº¡o Grad-CAM: {e}. Äiá»u nÃ y cÃ³ thá»ƒ do cáº¥u trÃºc model khÃ´ng nhÆ° mong Ä‘á»£i hoáº·c target_layer khÃ´ng tá»“n táº¡i.") #
        return None, None
    except Exception as e: #
        st.error(f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi táº¡o Grad-CAM: {e}") #
        return None, None

# --- Cáº¥u hÃ¬nh vÃ  HÃ m há»— trá»£ ---
def get_transform(img_size=224): #
    return transforms.Compose([ #
        transforms.Resize((img_size, img_size)), #
        transforms.ToTensor(), #
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #
    ])

@st.cache_resource #
def load_medmamba_model(checkpoint_path, num_classes): #
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") #
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False) #
        
        actual_num_classes = checkpoint.get('num_classes') #
        if actual_num_classes is None: #
            st.warning(f"Checkpoint khÃ´ng chá»©a 'num_classes'. Sá»­ dá»¥ng giÃ¡ trá»‹ Ä‘áº§u vÃ o: {num_classes}.") #
        elif actual_num_classes != num_classes: #
            st.warning(f"Sá»‘ lá»›p trong checkpoint ({actual_num_classes}) khÃ¡c vá»›i sá»‘ lá»›p nháº­p vÃ o ({num_classes}). Sá»­ dá»¥ng giÃ¡ trá»‹ tá»« checkpoint: {actual_num_classes}.") #
            num_classes = actual_num_classes #
            
        model = medmamba(num_classes=num_classes) #
        model.load_state_dict(checkpoint['model_state_dict']) #
        model.eval() #
        model.to(device) #
        
        class_indices_from_ckpt = checkpoint.get('class_indices') #
        if class_indices_from_ckpt and isinstance(class_indices_from_ckpt, dict): #
            if all(isinstance(k, int) for k in class_indices_from_ckpt.keys()): #
                 class_indices_from_ckpt = {str(k): v for k,v in class_indices_from_ckpt.items()} #
        
        st.success(f"MÃ´ hÃ¬nh Ä‘Æ°á»£c náº¡p thÃ nh cÃ´ng tá»« '{os.path.basename(checkpoint_path)}' trÃªn {device}.") #
        return model, device, class_indices_from_ckpt, num_classes #
    except FileNotFoundError: #
        st.error(f"KhÃ´ng tÃ¬m tháº¥y tá»‡p checkpoint táº¡i: {checkpoint_path}") #
    except KeyError as e: #
        st.error(f"Lá»—i KeyError khi náº¡p checkpoint (cÃ³ thá»ƒ thiáº¿u 'model_state_dict' hoáº·c 'num_classes'): {e}") #
    except Exception as e: #
        st.error(f"Lá»—i khi náº¡p mÃ´ hÃ¬nh: {e}") #
    return None, None, None, num_classes #


@st.cache_data #
def load_class_indices_from_file(class_indices_path): #
    if class_indices_path and os.path.exists(class_indices_path): #
        try:
            with open(class_indices_path, 'r') as f: #
                class_indices = json.load(f) #
            if isinstance(class_indices, dict) and any(isinstance(k, int) for k in class_indices.keys()): #
                 class_indices = {str(k): v for k,v in class_indices.items()} #
            st.info(f"ÄÃ£ náº¡p class_indices tá»« tá»‡p: {class_indices_path}") #
            return class_indices #
        except Exception as e: #
            st.warning(f"KhÃ´ng thá»ƒ náº¡p class_indices tá»« '{class_indices_path}': {e}") #
    return None #

def predict(model, device, image_pil, transform, class_indices): #
    img_tensor = transform(image_pil.convert('RGB')) #
    input_tensor = torch.unsqueeze(img_tensor, dim=0).to(device) #

    with torch.no_grad(): #
        output_logits = model(input_tensor) #
        probabilities = torch.softmax(output_logits, dim=1) #
        predicted_prob_tensor, predicted_idx_tensor = torch.max(probabilities, dim=1) #
        predicted_idx = predicted_idx_tensor.item() #
        predicted_confidence = predicted_prob_tensor.item() #

    predicted_class_name = str(predicted_idx) #
    if class_indices: #
        predicted_class_name = class_indices.get(str(predicted_idx), f"Lá»›p khÃ´ng xÃ¡c Ä‘á»‹nh (Index: {predicted_idx})") #
    
    return predicted_class_name, predicted_confidence, predicted_idx #

# --- Giao diá»‡n Streamlit ---
def main_app(): #
    st.set_page_config(page_title="Demo MedMamba", layout="wide") #
    st.title("ğŸ Demo PhÃ¢n Loáº¡i áº¢nh Y Táº¿ vá»›i MedMamba") #

    st.sidebar.header("âš™ï¸ Cáº¥u HÃ¬nh MÃ´ HÃ¬nh") #
    
    if 'checkpoint_path_input' not in st.session_state: #
        st.session_state.checkpoint_path_input = "YOUR_MODEL_CHECKPOINT.pth" #
    if 'class_indices_path_input' not in st.session_state: #
        st.session_state.class_indices_path_input = "class_indices.json" #
    if 'num_classes_input' not in st.session_state: #
        st.session_state.num_classes_input = 3 #
    
    st.session_state.checkpoint_path_input = st.sidebar.text_input( #
        "ÄÆ°á»ng dáº«n Ä‘áº¿n Checkpoint (.pth)", 
        value=st.session_state.checkpoint_path_input, #
        help="Cung cáº¥p Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§ Ä‘áº¿n tá»‡p checkpoint cá»§a mÃ´ hÃ¬nh MedMamba." #
    )
    # st.session_state.class_indices_path_input = st.sidebar.text_input( #
    #     "ÄÆ°á»ng dáº«n Ä‘áº¿n Class Indices (.json) (TÃ¹y chá»n)", 
    #     value=st.session_state.class_indices_path_input, #
    #     help="Tá»‡p JSON chá»©a Ã¡nh xáº¡ tá»« index sang tÃªn lá»›p." #
    # )
    # st.session_state.num_classes_input = st.sidebar.number_input( #
    #     "Sá»‘ LÆ°á»£ng Lá»›p (náº¿u khÃ´ng cÃ³ trong checkpoint)", 
    #     min_value=1, value=st.session_state.num_classes_input, step=1, #
    #     help="Sá»‘ lá»›p Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh. Sáº½ Ä‘Æ°á»£c ghi Ä‘Ã¨ náº¿u checkpoint chá»©a thÃ´ng tin nÃ y." #
    # )

    if 'model' not in st.session_state: #
        st.session_state.model = None #
        st.session_state.device = None #
        st.session_state.class_indices = None #
        st.session_state.num_classes_loaded = st.session_state.num_classes_input #
        st.session_state.model_loaded_path = "" #
        st.session_state.last_prediction_info = None #
        st.session_state.image_to_display_caption = "" # ThÃªm Ä‘á»ƒ lÆ°u caption áº£nh gá»‘c
        st.session_state.image_to_display_pil = None # ThÃªm Ä‘á»ƒ lÆ°u áº£nh gá»‘c PIL

    if st.sidebar.button("Náº¡p MÃ´ HÃ¬nh", key="load_model_button"): #
        st.session_state.model = None  #
        st.session_state.last_prediction_info = None  #
        st.session_state.image_to_display_pil = None #
        if st.session_state.checkpoint_path_input: #
            model, device, class_indices_from_ckpt, num_classes_final = load_medmamba_model( #
                st.session_state.checkpoint_path_input, 
                st.session_state.num_classes_input
            )
            
            if model and device: #
                st.session_state.model = model #
                st.session_state.device = device #
                st.session_state.num_classes_loaded = num_classes_final #
                st.session_state.model_loaded_path = st.session_state.checkpoint_path_input #

                class_indices_from_file = load_class_indices_from_file(st.session_state.class_indices_path_input) #
                if class_indices_from_file: #
                    st.session_state.class_indices = class_indices_from_file #
                elif class_indices_from_ckpt: #
                    st.session_state.class_indices = class_indices_from_ckpt #
                    st.sidebar.info("ÄÃ£ sá»­ dá»¥ng class_indices tá»« checkpoint.") #
                else: #
                    st.session_state.class_indices = None #
                    st.sidebar.warning("KhÃ´ng tÃ¬m tháº¥y class_indices. Dá»± Ä‘oÃ¡n sáº½ chá»‰ hiá»ƒn thá»‹ index cá»§a lá»›p.") #
            else: #
                st.session_state.model = None #
                st.session_state.class_indices = None #
        else: #
            st.sidebar.error("Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n Ä‘áº¿n checkpoint.") #

    if st.session_state.model is None: #
        st.warning("MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c náº¡p. Vui lÃ²ng cáº¥u hÃ¬nh vÃ  nháº¥n 'Náº¡p MÃ´ HÃ¬nh' trong thanh sidebar.") #
        st.stop() #

    st.success(f"MÃ´ hÃ¬nh **{os.path.basename(st.session_state.model_loaded_path)}** Ä‘Ã£ Ä‘Æ°á»£c náº¡p vÃ  sáºµn sÃ ng!") #
    st.info(f"Sá»‘ lá»›p cá»§a mÃ´ hÃ¬nh: **{st.session_state.num_classes_loaded}**") #
    if st.session_state.class_indices: #
        st.write("CÃ¡c lá»›p Ä‘Æ°á»£c phÃ¡t hiá»‡n:") #
        st.json(st.session_state.class_indices, expanded=False) #
    
    img_transform = get_transform() #

    st.markdown("---") #
    st.header("ğŸ”¬ Chá»n áº¢nh & Xem Káº¿t Quáº£ PhÃ¢n TÃ­ch") #
    
    prediction_mode = st.radio( #
        "Chá»n nguá»“n áº£nh:", #
        ("Táº£i áº¢nh LÃªn", "áº¢nh Ngáº«u NhiÃªn Tá»« ThÆ° Má»¥c"), #
        key="prediction_mode_radio",
        horizontal=True
    )

    # Xá»­ lÃ½ viá»‡c chá»n áº£nh vÃ  nÃºt báº¥m
    if prediction_mode == "Táº£i áº¢nh LÃªn": #
        uploaded_file = st.file_uploader( #
            "Chá»n má»™t hÃ¬nh áº£nh...", 
            type=["png", "jpg", "jpeg", "bmp"], #
            key="file_uploader",
            on_change=lambda: st.session_state.update(last_prediction_info=None, image_to_display_pil=None) # Reset khi cÃ³ file má»›i
        )
        if uploaded_file is not None: #
            try:
                st.session_state.image_to_display_pil = Image.open(uploaded_file).convert('RGB') #
                st.session_state.image_to_display_caption = "áº¢nh ÄÃ£ Táº£i LÃªn" #
            except Exception as e: #
                st.error(f"Lá»—i xá»­ lÃ½ áº£nh táº£i lÃªn: {e}") #
                st.session_state.image_to_display_pil = None #

    elif prediction_mode == "áº¢nh Ngáº«u NhiÃªn Tá»« ThÆ° Má»¥c": #
        if 'test_dir_input' not in st.session_state: #
            st.session_state.test_dir_input = "PATH_TO_YOUR_TEST_IMAGE_FOLDER" #

        st.session_state.test_dir_input = st.text_input( #
            "ÄÆ°á»ng dáº«n Ä‘áº¿n ThÆ° Má»¥c áº¢nh Test", 
            value=st.session_state.test_dir_input, #
            help="Cung cáº¥p Ä‘Æ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a cÃ¡c áº£nh Ä‘á»ƒ chá»n ngáº«u nhiÃªn." #
        )

        if st.button("Láº¥y áº¢nh Ngáº«u NhiÃªn, Dá»± ÄoÃ¡n & Hiá»‡n Grad-CAM", key="random_predict_gradcam_button"):
            st.session_state.last_prediction_info = None # Reset dá»± Ä‘oÃ¡n cÅ©
            st.session_state.image_to_display_pil = None
            if not os.path.isdir(st.session_state.test_dir_input): #
                st.error(f"KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c: {st.session_state.test_dir_input}") #
            else: #
                image_files = [] #
                for root, _, files in os.walk(st.session_state.test_dir_input): #
                    for file in files: #
                        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')): #
                            image_files.append(os.path.join(root, file)) #
                
                if not image_files: #
                    st.warning(f"KhÃ´ng tÃ¬m tháº¥y tá»‡p áº£nh nÃ o trong thÆ° má»¥c: {st.session_state.test_dir_input}") #
                else: #
                    random_image_path = random.choice(image_files) #
                    try:
                        random_pil_image = Image.open(random_image_path).convert('RGB') #
                        st.session_state.image_to_display_pil = random_pil_image #
                        st.session_state.image_to_display_caption = f"áº¢nh Ngáº«u NhiÃªn: {os.path.basename(random_image_path)}" #
                        
                        # Thá»±c hiá»‡n dá»± Ä‘oÃ¡n ngay sau khi láº¥y áº£nh
                        with st.spinner("Äang dá»± Ä‘oÃ¡n..."): #
                            class_name, confidence, class_idx = predict( #
                                st.session_state.model, #
                                st.session_state.device, #
                                st.session_state.image_to_display_pil, #
                                img_transform, #
                                st.session_state.class_indices #
                            )
                        st.session_state.last_prediction_info = { #
                            "image_pil": st.session_state.image_to_display_pil, #
                            "image_caption": st.session_state.image_to_display_caption, #
                            "class_name": class_name, #
                            "confidence": confidence, #
                            "predicted_idx": class_idx #
                        }
                    except Exception as e: #
                        st.error(f"Lá»—i xá»­ lÃ½ áº£nh {random_image_path}: {e}") #
                        st.session_state.image_to_display_pil = None #
    
    # NÃºt "Thá»±c Hiá»‡n Dá»± ÄoÃ¡n" cho áº£nh táº£i lÃªn
    if prediction_mode == "Táº£i áº¢nh LÃªn" and st.session_state.image_to_display_pil: #
        if st.button("Thá»±c Hiá»‡n Dá»± ÄoÃ¡n & Hiá»‡n Grad-CAM", key="upload_predict_gradcam_button"):
            st.session_state.last_prediction_info = None # Reset dá»± Ä‘oÃ¡n cÅ©
            with st.spinner("Äang dá»± Ä‘oÃ¡n..."): #
                class_name, confidence, class_idx = predict( #
                    st.session_state.model, #
                    st.session_state.device, #
                    st.session_state.image_to_display_pil, #
                    img_transform, #
                    st.session_state.class_indices #
                )
            st.session_state.last_prediction_info = { #
                "image_pil": st.session_state.image_to_display_pil, #
                "image_caption": st.session_state.image_to_display_caption, #
                "class_name": class_name, #
                "confidence": confidence, #
                "predicted_idx": class_idx #
            }

    # Hiá»ƒn thá»‹ áº£nh gá»‘c (náº¿u cÃ³)
    if st.session_state.get('image_to_display_pil') is not None:
        st.image(st.session_state.image_to_display_pil, caption=st.session_state.get('image_to_display_caption',"áº¢nh Ä‘Ã£ chá»n"), width=300) #
    elif prediction_mode == "Táº£i áº¢nh LÃªn":
        st.info("Vui lÃ²ng táº£i áº£nh lÃªn.")
    
    # --- Pháº§n hiá»ƒn thá»‹ káº¿t quáº£ vÃ  Grad-CAM ---
    last_prediction_info = st.session_state.get('last_prediction_info', None) #

    if last_prediction_info and last_prediction_info.get("image_pil") is not None: #
        st.markdown("---") #
        
        # ThÃ´ng tin dá»± Ä‘oÃ¡n hiá»ƒn thá»‹ á»Ÿ trÃªn
        st.subheader("Káº¿t Quáº£ Dá»± ÄoÃ¡n:") #
        target_idx_int = -1
        try:
            target_idx_int = int(target_category_input_gradcam)
        except:
            pass

        if st.session_state.class_indices and str(target_idx_int) in st.session_state.class_indices:
            target_class_name = st.session_state.class_indices[str(target_idx_int)]
            st.markdown(f"**TÃªn Lá»›p Má»¥c TiÃªu:** `{target_class_name}`")
        elif target_idx_int >= 0:
            st.markdown(f"**TÃªn Lá»›p Má»¥c TiÃªu:** _(KhÃ´ng xÃ¡c Ä‘á»‹nh - khÃ´ng cÃ³ Ã¡nh xáº¡ tÃªn lá»›p cho index nÃ y)_")
        st.markdown(f"**Lá»›p Dá»± ÄoÃ¡n:** `{last_prediction_info['class_name']}` (Index: {last_prediction_info['predicted_idx']})") #
        st.markdown(f"**Äá»™ Tin Cáº­y:** `{last_prediction_info['confidence']:.4f}`") #

        st.subheader("ğŸ”¥ Grad-CAM Visualization") #
        pil_image_for_gradcam = last_prediction_info["image_pil"] #
        predicted_idx_for_gradcam = last_prediction_info["predicted_idx"] #
        predicted_class_name_display_gradcam = last_prediction_info["class_name"] #
        
        # Sá»­ dá»¥ng id cá»§a áº£nh lÃ m pháº§n cá»§a key Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh duy nháº¥t khi áº£nh thay Ä‘á»•i
        target_category_key = f"target_category_gradcam_input_for_{id(pil_image_for_gradcam)}_{predicted_idx_for_gradcam}" #
        
        # Láº¥y giÃ¡ trá»‹ hiá»‡n táº¡i tá»« session_state hoáº·c dÃ¹ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh
        current_input_value_for_gradcam = st.session_state.get(target_category_key, str(predicted_idx_for_gradcam)) #

        target_category_input_gradcam = st.text_input( #
            f"Index Lá»›p Má»¥c TiÃªu cho Grad-CAM (máº·c Ä‘á»‹nh: lá»›p dá»± Ä‘oÃ¡n - '{predicted_class_name_display_gradcam}' (Index: {predicted_idx_for_gradcam}))", #
            key=target_category_key, #
            value=current_input_value_for_gradcam # 
        )
        
        target_category_for_gradcam = predicted_idx_for_gradcam #
        if target_category_input_gradcam.strip(): #
            try:
                target_category_for_gradcam = int(target_category_input_gradcam) #
            except ValueError: #
                st.warning(f"GiÃ¡ trá»‹ '{target_category_input_gradcam}' khÃ´ng há»£p lá»‡ cho Target Category. Sá»­ dá»¥ng index lá»›p Ä‘Æ°á»£c dá»± Ä‘oÃ¡n ({predicted_idx_for_gradcam}).") #
        
        num_classes_loaded = st.session_state.num_classes_loaded #
        if not (0 <= target_category_for_gradcam < num_classes_loaded): #
            st.error(f"Target Category Index ({target_category_for_gradcam}) náº±m ngoÃ i khoáº£ng há»£p lá»‡ [0, {num_classes_loaded-1}]. Vui lÃ²ng chá»n má»™t index há»£p lá»‡.") #
        else: #
            with st.spinner("Äang táº¡o Grad-CAM..."): #
                original_img_display, cam_image = generate_gradcam_image( #
                    st.session_state.model, #
                    st.session_state.device, #
                    pil_image_for_gradcam, #
                    target_category_for_gradcam, #
                    st.session_state.class_indices, #
                    img_size=224
                )

            if original_img_display is not None and cam_image is not None: #
                target_gradcam_class_name_display = str(target_category_for_gradcam) #
                if st.session_state.class_indices: #
                    target_gradcam_class_name_display = st.session_state.class_indices.get(str(target_category_for_gradcam), str(target_category_for_gradcam)) #
                
                # Hiá»ƒn thá»‹ áº£nh gá»‘c vÃ  Grad-CAM cáº¡nh nhau
                col_img1, col_img2 = st.columns(2)
                with col_img1:
                    st.image(original_img_display, caption=last_prediction_info.get("image_caption", "áº¢nh Ä‘Ã£ xá»­ lÃ½"), use_container_width=True) #
                with col_img2:
                    st.image(cam_image, caption=f"Grad-CAM cho lá»›p: {target_gradcam_class_name_display}", use_container_width=True) #
            # Lá»—i Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ bÃªn trong generate_gradcam_image
    
    st.sidebar.markdown("---") #
    st.sidebar.markdown("ÄÆ°á»£c há»— trá»£ bá»Ÿi Äá»‘i tÃ¡c Láº­p trÃ¬nh Gemini") #

if __name__ == '__main__': #
    main_app() #