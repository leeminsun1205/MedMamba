import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
import os
import random
import json
import cv2

from grad_cam.utils import GradCAM, show_cam_on_image

from MedMamba import VSSM as medmamba

# --- L·ªõp v√† H√†m cho Grad-CAM ---
class MedMambaReshapeTransform: #
    """
    Reshape transform cho MedMamba, ƒëi·ªÅu ch·ªânh tensor n·∫øu n√≥ c√≥ d·∫°ng (B, H, W, C)
    thay v√¨ (B, C, H, W) m√† GradCAM mong ƒë·ª£i cho m·ªôt s·ªë b∆∞·ªõc trung gian.
    """
    def __call__(self, x: torch.Tensor) -> torch.Tensor:
        if x.ndim == 4: #
            if x.shape[1] == x.shape[2] and x.shape[1] > x.shape[3]: # (B, H, W, C)
                return x.permute(0, 3, 1, 2) # Chuy·ªÉn th√†nh (B, C, H, W)
        return x

def generate_gradcam_image(model, device, pil_image, target_category_for_gradcam, class_indices,
                           img_size=224, smooth_cam=False, gaussian_ksize=7):
    try:
        if not (hasattr(model, 'layers') and model.layers and
                len(model.layers) > 0 and hasattr(model.layers[-1], 'blocks') and
                model.layers[-1].blocks and len(model.layers[-1].blocks) > 0 and
                hasattr(model.layers[-1].blocks[-1], 'conv33conv33conv11') and
                model.layers[-1].blocks[-1].conv33conv33conv11 and
                len(model.layers[-1].blocks[-1].conv33conv33conv11) >= 2):
            st.error("C·∫•u tr√∫c model kh√¥ng ph√π h·ª£p ho·∫∑c kh√¥ng ƒë·ªß s√¢u ƒë·ªÉ l·∫•y target_layer cho Grad-CAM (v√≠ d·ª•: model.layers[-1].blocks[-1].conv33conv33conv11[-2]).")
            return None, None
        
        target_layer = model.layers[-1].blocks[-1].conv33conv33conv11[-2] #
        target_layers = [target_layer] #

        # 2. Chu·∫©n b·ªã ·∫£nh ƒë·∫ßu v√†o
        data_transform_gradcam = transforms.Compose([ #
            transforms.Resize((img_size, img_size)), #
            transforms.ToTensor(), #
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #
        ])
        img_tensor_transformed = data_transform_gradcam(pil_image.convert('RGB')) #
        input_tensor = torch.unsqueeze(img_tensor_transformed, dim=0).to(device) #

        # Chu·∫©n b·ªã ·∫£nh ƒë·ªÉ hi·ªÉn th·ªã (unnormalized)
        img_for_display_unnormalized = img_tensor_transformed.cpu().clone() #
        mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1) #
        std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1) #
        img_for_display_unnormalized = img_for_display_unnormalized * std + mean #
        img_for_display_unnormalized = torch.clamp(img_for_display_unnormalized, 0, 1) #
        img_for_display = img_for_display_unnormalized.permute(1, 2, 0).numpy() #

        # 3. Kh·ªüi t·∫°o GradCAM
        reshape_transform = MedMambaReshapeTransform() #
        cam_algorithm = GradCAM(model=model, #
                                target_layers=target_layers, #
                                use_cuda=torch.cuda.is_available(), #
                                reshape_transform=reshape_transform) #

        # 4. T√≠nh to√°n Grad-CAM
        # ƒê·∫£m b·∫£o model ƒëang ·ªü ch·∫ø ƒë·ªô eval
        model.eval()
        grayscale_cam = cam_algorithm(input_tensor=input_tensor, target_category=target_category_for_gradcam) #
        
        if grayscale_cam is None: #
            st.error("Grad-CAM kh√¥ng t·∫°o ra output. ƒêi·ªÅu n√†y c√≥ th·ªÉ x·∫£y ra n·∫øu target_layer kh√¥ng ph√π h·ª£p ho·∫∑c gradient l√† zero.")
            return None, None
        grayscale_cam = grayscale_cam[0, :] #

        # 5. L√†m m·ªãn (n·∫øu c√≥) v√† ph·ªß m√†u
        if smooth_cam: #
            ksize = gaussian_ksize #
            if ksize % 2 == 0: ksize +=1 # # Kernel size ph·∫£i l√† s·ªë l·∫ª
            grayscale_cam = cv2.GaussianBlur(grayscale_cam, (ksize, ksize), 0) #

        cam_image_result = show_cam_on_image(img_for_display, grayscale_cam, use_rgb=True) #

        return img_for_display, cam_image_result

    except AttributeError as e:
        st.error(f"L·ªói thu·ªôc t√≠nh khi t·∫°o Grad-CAM: {e}. ƒêi·ªÅu n√†y c√≥ th·ªÉ do c·∫•u tr√∫c model kh√¥ng nh∆∞ mong ƒë·ª£i ho·∫∑c target_layer kh√¥ng t·ªìn t·∫°i.")
        return None, None
    except Exception as e:
        st.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫°o Grad-CAM: {e}")
        return None, None

# --- C·∫•u h√¨nh v√† H√†m h·ªó tr·ª£ (Gi·ªØ nguy√™n t·ª´ file g·ªëc c·ªßa b·∫°n) ---
def get_transform(img_size=224): #
    """Tr·∫£ v·ªÅ transform chu·∫©n cho ·∫£nh ƒë·∫ßu v√†o."""
    return transforms.Compose([ #
        transforms.Resize((img_size, img_size)), #
        transforms.ToTensor(), #
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #
    ])

@st.cache_resource #
def load_medmamba_model(checkpoint_path, num_classes): #
    """N·∫°p m√¥ h√¨nh MedMamba t·ª´ checkpoint."""
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") #
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False) #
        
        actual_num_classes = checkpoint.get('num_classes') #
        if actual_num_classes is None: #
            st.warning(f"Checkpoint kh√¥ng ch·ª©a 'num_classes'. S·ª≠ d·ª•ng gi√° tr·ªã ƒë·∫ßu v√†o: {num_classes}.") #
        elif actual_num_classes != num_classes: #
            st.warning(f"S·ªë l·ªõp trong checkpoint ({actual_num_classes}) kh√°c v·ªõi s·ªë l·ªõp nh·∫≠p v√†o ({num_classes}). S·ª≠ d·ª•ng gi√° tr·ªã t·ª´ checkpoint: {actual_num_classes}.") #
            num_classes = actual_num_classes #
            
        model = medmamba(num_classes=num_classes) #
        model.load_state_dict(checkpoint['model_state_dict']) #
        model.eval() #
        model.to(device) #
        
        class_indices_from_ckpt = checkpoint.get('class_indices') #
        if class_indices_from_ckpt and isinstance(class_indices_from_ckpt, dict): #
            if all(isinstance(k, int) for k in class_indices_from_ckpt.keys()): #
                 class_indices_from_ckpt = {str(k): v for k,v in class_indices_from_ckpt.items()} #
        
        st.success(f"M√¥ h√¨nh ƒë∆∞·ª£c n·∫°p th√†nh c√¥ng t·ª´ '{os.path.basename(checkpoint_path)}' tr√™n {device}.") #
        return model, device, class_indices_from_ckpt, num_classes #
    except FileNotFoundError: #
        st.error(f"Kh√¥ng t√¨m th·∫•y t·ªáp checkpoint t·∫°i: {checkpoint_path}") #
    except KeyError as e: #
        st.error(f"L·ªói KeyError khi n·∫°p checkpoint (c√≥ th·ªÉ thi·∫øu 'model_state_dict' ho·∫∑c 'num_classes'): {e}") #
    except Exception as e: #
        st.error(f"L·ªói khi n·∫°p m√¥ h√¨nh: {e}") #
    return None, None, None, num_classes #


@st.cache_data #
def load_class_indices_from_file(class_indices_path): #
    """N·∫°p class_indices t·ª´ t·ªáp JSON ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh."""
    if class_indices_path and os.path.exists(class_indices_path): #
        try:
            with open(class_indices_path, 'r') as f: #
                class_indices = json.load(f) #
            if isinstance(class_indices, dict) and any(isinstance(k, int) for k in class_indices.keys()): #
                 class_indices = {str(k): v for k,v in class_indices.items()} #
            st.info(f"ƒê√£ n·∫°p class_indices t·ª´ t·ªáp: {class_indices_path}") #
            return class_indices #
        except Exception as e: #
            st.warning(f"Kh√¥ng th·ªÉ n·∫°p class_indices t·ª´ '{class_indices_path}': {e}") #
    return None #

def predict(model, device, image_pil, transform, class_indices): #
    """Th·ª±c hi·ªán d·ª± ƒëo√°n tr√™n ·∫£nh PIL ƒë√£ cho."""
    img_tensor = transform(image_pil.convert('RGB')) #
    input_tensor = torch.unsqueeze(img_tensor, dim=0).to(device) #

    with torch.no_grad(): #
        output_logits = model(input_tensor) #
        probabilities = torch.softmax(output_logits, dim=1) #
        predicted_prob_tensor, predicted_idx_tensor = torch.max(probabilities, dim=1) #
        predicted_idx = predicted_idx_tensor.item() #
        predicted_confidence = predicted_prob_tensor.item() #

    predicted_class_name = str(predicted_idx) #
    if class_indices: #
        predicted_class_name = class_indices.get(str(predicted_idx), f"L·ªõp kh√¥ng x√°c ƒë·ªãnh (Index: {predicted_idx})") #
    
    return predicted_class_name, predicted_confidence, predicted_idx #

# --- Giao di·ªán Streamlit ---
def main_app(): #
    st.set_page_config(page_title="Demo MedMamba", layout="wide") #
    st.title("üêç Demo Ph√¢n Lo·∫°i ·∫¢nh Y T·∫ø v·ªõi MedMamba") #

    st.sidebar.header("‚öôÔ∏è C·∫•u H√¨nh M√¥ H√¨nh") #
    
    default_checkpoint_path = "YOUR_MODEL_CHECKPOINT.pth" #
    default_class_indices_path = "class_indices.json" #
    
    checkpoint_path_input = st.sidebar.text_input( #
        "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Checkpoint (.pth)", 
        value=default_checkpoint_path, #
        help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn t·ªáp checkpoint c·ªßa m√¥ h√¨nh MedMamba." #
    )
    class_indices_path_input = st.sidebar.text_input( #
        "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Class Indices (.json) (T√πy ch·ªçn)", 
        value=default_class_indices_path, #
        help="T·ªáp JSON ch·ª©a √°nh x·∫° t·ª´ index sang t√™n l·ªõp." #
    )
    num_classes_input = st.sidebar.number_input( #
        "S·ªë L∆∞·ª£ng L·ªõp (n·∫øu kh√¥ng c√≥ trong checkpoint)", 
        min_value=1, value=3, step=1, #
        help="S·ªë l·ªõp ƒë·∫ßu ra c·ªßa m√¥ h√¨nh. S·∫Ω ƒë∆∞·ª£c ghi ƒë√® n·∫øu checkpoint ch·ª©a th√¥ng tin n√†y." #
    )

    if 'model' not in st.session_state: #
        st.session_state.model = None #
        st.session_state.device = None #
        st.session_state.class_indices = None #
        st.session_state.num_classes_loaded = num_classes_input #
        st.session_state.model_loaded_path = "" #
        st.session_state.last_prediction_info = None # Kh·ªüi t·∫°o cho Grad-CAM

    if st.sidebar.button("N·∫°p M√¥ H√¨nh & Class Indices", key="load_model_button"): #
        st.session_state.model = None #
        st.session_state.last_prediction_info = None # Reset khi n·∫°p model m·ªõi
        if checkpoint_path_input: #
            model, device, class_indices_from_ckpt, num_classes_final = load_medmamba_model(checkpoint_path_input, num_classes_input) #
            
            if model and device: #
                st.session_state.model = model #
                st.session_state.device = device #
                st.session_state.num_classes_loaded = num_classes_final #
                st.session_state.model_loaded_path = checkpoint_path_input #

                class_indices_from_file = load_class_indices_from_file(class_indices_path_input) #
                if class_indices_from_file: #
                    st.session_state.class_indices = class_indices_from_file #
                elif class_indices_from_ckpt: #
                    st.session_state.class_indices = class_indices_from_ckpt #
                    st.sidebar.info("ƒê√£ s·ª≠ d·ª•ng class_indices t·ª´ checkpoint.") #
                else: #
                    st.session_state.class_indices = None #
                    st.sidebar.warning("Kh√¥ng t√¨m th·∫•y class_indices. D·ª± ƒëo√°n s·∫Ω ch·ªâ hi·ªÉn th·ªã index c·ªßa l·ªõp.") #
            else: #
                st.session_state.model = None #
                st.session_state.class_indices = None #
        else: #
            st.sidebar.error("Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn checkpoint.") #

    if st.session_state.model is None: #
        st.warning("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c n·∫°p. Vui l√≤ng c·∫•u h√¨nh v√† nh·∫•n 'N·∫°p M√¥ H√¨nh' trong thanh sidebar.") #
        st.stop() #

    st.success(f"M√¥ h√¨nh **{os.path.basename(st.session_state.model_loaded_path)}** ƒë√£ ƒë∆∞·ª£c n·∫°p v√† s·∫µn s√†ng!") #
    st.info(f"S·ªë l·ªõp c·ªßa m√¥ h√¨nh: **{st.session_state.num_classes_loaded}**") #
    if st.session_state.class_indices: #
        st.write("C√°c l·ªõp ƒë∆∞·ª£c ph√°t hi·ªán:") #
        st.json(st.session_state.class_indices, expanded=False) #
    
    img_transform = get_transform() #

    st.markdown("---") #
    st.header("üî¨ Ch·∫ø ƒê·ªô D·ª± ƒêo√°n") #
    prediction_mode = st.radio( #
        "Ch·ªçn ch·∫ø ƒë·ªô d·ª± ƒëo√°n:", #
        ("T·∫£i ·∫¢nh L√™n", "D·ª± ƒêo√°n ·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c"), #
        key="prediction_mode_radio" #
    )

    image_pil_for_prediction = None

    if prediction_mode == "T·∫£i ·∫¢nh L√™n": #
        uploaded_file = st.file_uploader( #
            "Ch·ªçn m·ªôt h√¨nh ·∫£nh...", 
            type=["png", "jpg", "jpeg", "bmp"], #
            key="file_uploader" #
        )
        if uploaded_file is not None: #
            try:
                image_pil_for_prediction = Image.open(uploaded_file).convert('RGB') #
                
                col1, col2 = st.columns([2,3]) #
                with col1: #
                    st.image(image_pil_for_prediction, caption="·∫¢nh ƒê√£ T·∫£i L√™n", use_column_width=True) #

                with col2: #
                    if st.button("Th·ª±c Hi·ªán D·ª± ƒêo√°n", key="predict_uploaded_button"): #
                        with st.spinner("ƒêang d·ª± ƒëo√°n..."): #
                            class_name, confidence, class_idx = predict( #
                                st.session_state.model, #
                                st.session_state.device, #
                                image_pil_for_prediction, #
                                img_transform, #
                                st.session_state.class_indices #
                            )
                        st.session_state.last_prediction_info = { #
                            "image_pil": image_pil_for_prediction, #
                            "class_name": class_name, #
                            "confidence": confidence, #
                            "predicted_idx": class_idx #
                        }
                        st.subheader("K·∫øt Qu·∫£ D·ª± ƒêo√°n:") #
                        st.markdown(f"**L·ªõp D·ª± ƒêo√°n:** `{class_name}` (Index: {class_idx})") #
                        st.markdown(f"**ƒê·ªô Tin C·∫≠y:** `{confidence:.4f}`") #
            except Exception as e: #
                st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh t·∫£i l√™n: {e}") #

    elif prediction_mode == "D·ª± ƒêo√°n ·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c": #
        default_test_dir = "PATH_TO_YOUR_TEST_IMAGE_FOLDER" #
        test_dir_input = st.text_input( #
            "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Th∆∞ M·ª•c ·∫¢nh Test", 
            value=default_test_dir, #
            help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c ·∫£nh ƒë·ªÉ ch·ªçn ng·∫´u nhi√™n." #
        )

        if st.button("D·ª± ƒêo√°n ·∫¢nh Ng·∫´u Nhi√™n", key="predict_random_button"): #
            if not os.path.isdir(test_dir_input): #
                st.error(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {test_dir_input}") #
            else: #
                image_files = [] #
                for root, _, files in os.walk(test_dir_input): #
                    for file in files: #
                        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')): #
                            image_files.append(os.path.join(root, file)) #
                
                if not image_files: #
                    st.warning(f"Kh√¥ng t√¨m th·∫•y t·ªáp ·∫£nh n√†o trong th∆∞ m·ª•c: {test_dir_input}") #
                else: #
                    random_image_path = random.choice(image_files) #
                    try:
                        image_pil_for_prediction = Image.open(random_image_path).convert('RGB') #
                        
                        col1, col2 = st.columns([2,3]) #
                        with col1: #
                            st.image(image_pil_for_prediction, caption=f"·∫¢nh Ng·∫´u Nhi√™n: {os.path.basename(random_image_path)}", use_column_width=True) #
                        
                        with col2: #
                            with st.spinner("ƒêang d·ª± ƒëo√°n..."): #
                                class_name, confidence, class_idx = predict( #
                                    st.session_state.model, #
                                    st.session_state.device, #
                                    image_pil_for_prediction, #
                                    img_transform, #
                                    st.session_state.class_indices #
                                )
                            st.session_state.last_prediction_info = { #
                                "image_pil": image_pil_for_prediction, #
                                "class_name": class_name, #
                                "confidence": confidence, #
                                "predicted_idx": class_idx #
                            }
                            st.subheader("K·∫øt Qu·∫£ D·ª± ƒêo√°n:") #
                            st.markdown(f"**·∫¢nh ƒê∆∞·ª£c Ch·ªçn:** `{os.path.basename(random_image_path)}`") #
                            st.markdown(f"**L·ªõp D·ª± ƒêo√°n:** `{class_name}` (Index: {class_idx})") #
                            st.markdown(f"**ƒê·ªô Tin C·∫≠y:** `{confidence:.4f}`") #
                    except Exception as e: #
                        st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh {random_image_path}: {e}") #
    
    # --- Ph·∫ßn Grad-CAM ---
    st.markdown("---")
    st.header("üî• Grad-CAM Visualization (T√πy Ch·ªçn)")

    last_prediction_info = st.session_state.get('last_prediction_info', None)

    enable_gradcam = st.checkbox("B·∫≠t Grad-CAM", key="enable_gradcam_checkbox")

    if enable_gradcam:
        if not last_prediction_info or last_prediction_info.get("image_pil") is None:
            st.warning("Vui l√≤ng th·ª±c hi·ªán m·ªôt d·ª± ƒëo√°n v·ªõi ·∫£nh h·ª£p l·ªá tr∆∞·ªõc khi t·∫°o Grad-CAM.")
        else:
            pil_image_for_gradcam = last_prediction_info["image_pil"]
            predicted_idx_for_gradcam = last_prediction_info["predicted_idx"]
            
            predicted_class_name_display = last_prediction_info["class_name"]

            target_category_input_gradcam = st.text_input(
                f"Index L·ªõp M·ª•c Ti√™u cho Grad-CAM (m·∫∑c ƒë·ªãnh: l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n - '{predicted_class_name_display}' (Index: {predicted_idx_for_gradcam}))",
                key="target_category_gradcam_input",
                placeholder=str(predicted_idx_for_gradcam)
            )

            target_category_for_gradcam = predicted_idx_for_gradcam
            if target_category_input_gradcam:
                try:
                    target_category_for_gradcam = int(target_category_input_gradcam)
                except ValueError:
                    st.warning(f"Gi√° tr·ªã '{target_category_input_gradcam}' kh√¥ng h·ª£p l·ªá cho Target Category. S·ª≠ d·ª•ng index l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n ({predicted_idx_for_gradcam}).")
                    target_category_for_gradcam = predicted_idx_for_gradcam
            
            num_classes_loaded = st.session_state.num_classes_loaded
            if not (0 <= target_category_for_gradcam < num_classes_loaded):
                st.error(f"Target Category Index ({target_category_for_gradcam}) n·∫±m ngo√†i kho·∫£ng h·ª£p l·ªá [0, {num_classes_loaded-1}]. Vui l√≤ng ch·ªçn m·ªôt index h·ª£p l·ªá.")
            else:
                smooth_cam_gradcam = st.checkbox("L√†m m·ªãn b·∫£n ƒë·ªì CAM (Smooth CAM)", value=False, key="smooth_cam_checkbox") #
                gaussian_ksize_gradcam = 7
                if smooth_cam_gradcam: #
                    gaussian_ksize_gradcam = st.number_input( #
                        "K√≠ch th∆∞·ªõc Kernel Gaussian (s·ªë l·∫ª)", 
                        min_value=3, max_value=21, value=7, step=2, 
                        key="gaussian_ksize_gradcam_input"
                    )

                if st.button("T·∫°o Grad-CAM", key="generate_gradcam_button"):
                    with st.spinner("ƒêang t·∫°o Grad-CAM..."):
                        original_img_display, cam_image = generate_gradcam_image(
                            st.session_state.model,
                            st.session_state.device,
                            pil_image_for_gradcam,
                            target_category_for_gradcam,
                            st.session_state.class_indices,
                            img_size=224, # C√≥ th·ªÉ ƒë·∫∑t l√†m tham s·ªë c·∫•u h√¨nh n·∫øu mu·ªën
                            smooth_cam=smooth_cam_gradcam,
                            gaussian_ksize=gaussian_ksize_gradcam
                        )

                    if original_img_display is not None and cam_image is not None:
                        st.subheader("K·∫øt Qu·∫£ Grad-CAM")
                        
                        target_gradcam_class_name_display = str(target_category_for_gradcam)
                        if st.session_state.class_indices:
                            target_gradcam_class_name_display = st.session_state.class_indices.get(str(target_category_for_gradcam), str(target_category_for_gradcam))
                        
                        col_gradcam1, col_gradcam2 = st.columns(2)
                        with col_gradcam1:
                            caption_original = f"·∫¢nh G·ªëc"
                            if last_prediction_info:
                                caption_original += f"\nD·ª± ƒëo√°n: {last_prediction_info['class_name']} ({last_prediction_info['confidence']:.2f})"
                            st.image(original_img_display, caption=caption_original, use_column_width=True)
                        with col_gradcam2:
                            smooth_text = " (L√†m m·ªãn)" if smooth_cam_gradcam else "" #
                            st.image(cam_image, caption=f"Grad-CAM cho l·ªõp: {target_gradcam_class_name_display}{smooth_text}", use_column_width=True)
                    # Kh√¥ng c·∫ßn else ·ªü ƒë√¢y v√¨ generate_gradcam_image ƒë√£ hi·ªÉn th·ªã l·ªói b·∫±ng st.error()
    
    st.sidebar.markdown("---") #
    st.sidebar.markdown("ƒê∆∞·ª£c h·ªó tr·ª£ b·ªüi ƒê·ªëi t√°c L·∫≠p tr√¨nh Gemini") #

if __name__ == '__main__': #
    main_app() #