import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
import os
import random
import json
import cv2
import numpy as np

# Gi·∫£ s·ª≠ c√°c file utils.py c·ªßa grad_cam n·∫±m trong th∆∞ m·ª•c MedMamba/grad_cam/
# v√† app_streamlit_demo.py n·∫±m trong MedMamba/
try:
    from grad_cam.utils import GradCAM, show_cam_on_image #
except ImportError:
    st.error("Kh√¥ng th·ªÉ import GradCAM ho·∫∑c show_cam_on_image t·ª´ grad_cam.utils. ƒê·∫£m b·∫£o th∆∞ m·ª•c grad_cam v√† file utils.py ·ªü ƒë√∫ng v·ªã tr√≠ (v√≠ d·ª•: MedMamba/grad_cam/utils.py).") #
    st.stop()


# Gi·∫£ s·ª≠ MedMamba.py n·∫±m c√πng c·∫•p ho·∫∑c trong PYTHONPATH
try:
    from MedMamba import VSSM as medmamba #
except ImportError:
    st.error("Kh√¥ng th·ªÉ import MedMamba. H√£y ƒë·∫£m b·∫£o MedMamba.py ·ªü ƒë√∫ng v·ªã tr√≠.") #
    st.stop() #

# --- L·ªõp v√† H√†m cho Grad-CAM ---
class MedMambaReshapeTransform: #
    def __call__(self, x: torch.Tensor) -> torch.Tensor: #
        if x.ndim == 4: #
            if x.shape[1] == x.shape[2] and x.shape[1] > x.shape[3]: # (B, H, W, C)
                return x.permute(0, 3, 1, 2) # Chuy·ªÉn th√†nh (B, C, H, W)
        return x #

def generate_gradcam_image(model, device, pil_image, target_category_for_gradcam, class_indices,
                           img_size=224): #
    try:
        if not (hasattr(model, 'layers') and model.layers and
                len(model.layers) > 0 and hasattr(model.layers[-1], 'blocks') and
                model.layers[-1].blocks and len(model.layers[-1].blocks) > 0 and
                hasattr(model.layers[-1].blocks[-1], 'conv33conv33conv11') and
                model.layers[-1].blocks[-1].conv33conv33conv11 and
                len(model.layers[-1].blocks[-1].conv33conv33conv11) >= 2): #
            st.error("C·∫•u tr√∫c model kh√¥ng ph√π h·ª£p ho·∫∑c kh√¥ng ƒë·ªß s√¢u ƒë·ªÉ l·∫•y target_layer cho Grad-CAM (v√≠ d·ª•: model.layers[-1].blocks[-1].conv33conv33conv11[-2]).") #
            return None, None
        
        target_layer = model.layers[-1].blocks[-1].conv33conv33conv11[-2] #
        target_layers = [target_layer] #

        data_transform_gradcam = transforms.Compose([ #
            transforms.Resize((img_size, img_size)), #
            transforms.ToTensor(), #
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #
        ])
        img_tensor_transformed = data_transform_gradcam(pil_image.convert('RGB')) #
        input_tensor = torch.unsqueeze(img_tensor_transformed, dim=0).to(device) #

        img_for_display_unnormalized = img_tensor_transformed.cpu().clone() #
        mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1) #
        std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1) #
        img_for_display_unnormalized = img_for_display_unnormalized * std + mean #
        img_for_display_unnormalized = torch.clamp(img_for_display_unnormalized, 0, 1) #
        img_for_display = img_for_display_unnormalized.permute(1, 2, 0).numpy() #

        reshape_transform = MedMambaReshapeTransform() #
        cam_algorithm = GradCAM(model=model, #
                                target_layers=target_layers, #
                                use_cuda=torch.cuda.is_available(), #
                                reshape_transform=reshape_transform) #

        model.eval() #
        grayscale_cam = cam_algorithm(input_tensor=input_tensor, target_category=target_category_for_gradcam) #
        
        if grayscale_cam is None: #
            st.error("Grad-CAM kh√¥ng t·∫°o ra output. ƒêi·ªÅu n√†y c√≥ th·ªÉ x·∫£y ra n·∫øu target_layer kh√¥ng ph√π h·ª£p ho·∫∑c gradient l√† zero.") #
            return None, None
        grayscale_cam = grayscale_cam[0, :] #

        cam_image_result = show_cam_on_image(img_for_display, grayscale_cam, use_rgb=True) #

        return img_for_display, cam_image_result #

    except AttributeError as e: #
        st.error(f"L·ªói thu·ªôc t√≠nh khi t·∫°o Grad-CAM: {e}. ƒêi·ªÅu n√†y c√≥ th·ªÉ do c·∫•u tr√∫c model kh√¥ng nh∆∞ mong ƒë·ª£i ho·∫∑c target_layer kh√¥ng t·ªìn t·∫°i.") #
        return None, None
    except Exception as e: #
        st.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫°o Grad-CAM: {e}") #
        return None, None

# --- C·∫•u h√¨nh v√† H√†m h·ªó tr·ª£ ---
def get_transform(img_size=224): #
    return transforms.Compose([ #
        transforms.Resize((img_size, img_size)), #
        transforms.ToTensor(), #
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #
    ])

@st.cache_resource #
def load_medmamba_model(checkpoint_path, num_classes): #
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") #
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False) #
        
        actual_num_classes = checkpoint.get('num_classes') #
        if actual_num_classes is None: #
            st.warning(f"Checkpoint kh√¥ng ch·ª©a 'num_classes'. S·ª≠ d·ª•ng gi√° tr·ªã ƒë·∫ßu v√†o: {num_classes}.") #
        elif actual_num_classes != num_classes: #
            st.warning(f"S·ªë l·ªõp trong checkpoint ({actual_num_classes}) kh√°c v·ªõi s·ªë l·ªõp nh·∫≠p v√†o ({num_classes}). S·ª≠ d·ª•ng gi√° tr·ªã t·ª´ checkpoint: {actual_num_classes}.") #
            num_classes = actual_num_classes #
            
        model = medmamba(num_classes=num_classes) #
        model.load_state_dict(checkpoint['model_state_dict']) #
        model.eval() #
        model.to(device) #
        
        class_indices_from_ckpt = checkpoint.get('class_indices') #
        if class_indices_from_ckpt and isinstance(class_indices_from_ckpt, dict): #
            if all(isinstance(k, int) for k in class_indices_from_ckpt.keys()): #
                 class_indices_from_ckpt = {str(k): v for k,v in class_indices_from_ckpt.items()} #
        
        st.success(f"M√¥ h√¨nh ƒë∆∞·ª£c n·∫°p th√†nh c√¥ng t·ª´ '{os.path.basename(checkpoint_path)}' tr√™n {device}.") #
        return model, device, class_indices_from_ckpt, num_classes #
    except FileNotFoundError: #
        st.error(f"Kh√¥ng t√¨m th·∫•y t·ªáp checkpoint t·∫°i: {checkpoint_path}") #
    except KeyError as e: #
        st.error(f"L·ªói KeyError khi n·∫°p checkpoint (c√≥ th·ªÉ thi·∫øu 'model_state_dict' ho·∫∑c 'num_classes'): {e}") #
    except Exception as e: #
        st.error(f"L·ªói khi n·∫°p m√¥ h√¨nh: {e}") #
    return None, None, None, num_classes #


@st.cache_data #
def load_class_indices_from_file(class_indices_path): #
    if class_indices_path and os.path.exists(class_indices_path): #
        try:
            with open(class_indices_path, 'r') as f: #
                class_indices = json.load(f) #
            if isinstance(class_indices, dict) and any(isinstance(k, int) for k in class_indices.keys()): #
                 class_indices = {str(k): v for k,v in class_indices.items()} #
            st.info(f"ƒê√£ n·∫°p class_indices t·ª´ t·ªáp: {class_indices_path}") #
            return class_indices #
        except Exception as e: #
            st.warning(f"Kh√¥ng th·ªÉ n·∫°p class_indices t·ª´ '{class_indices_path}': {e}") #
    return None #

def predict(model, device, image_pil, transform, class_indices): #
    img_tensor = transform(image_pil.convert('RGB')) #
    input_tensor = torch.unsqueeze(img_tensor, dim=0).to(device) #

    with torch.no_grad(): #
        output_logits = model(input_tensor) #
        probabilities = torch.softmax(output_logits, dim=1) #
        predicted_prob_tensor, predicted_idx_tensor = torch.max(probabilities, dim=1) #
        predicted_idx = predicted_idx_tensor.item() #
        predicted_confidence = predicted_prob_tensor.item() #

    predicted_class_name = str(predicted_idx) #
    if class_indices: #
        predicted_class_name = class_indices.get(str(predicted_idx), f"L·ªõp kh√¥ng x√°c ƒë·ªãnh (Index: {predicted_idx})") #
    
    return predicted_class_name, predicted_confidence, predicted_idx #

# --- Giao di·ªán Streamlit ---
def main_app(): #
    st.set_page_config(page_title="Demo MedMamba", layout="wide") #
    st.title("üêç Demo Ph√¢n Lo·∫°i ·∫¢nh Y T·∫ø v·ªõi MedMamba") #

    st.sidebar.header("‚öôÔ∏è C·∫•u H√¨nh M√¥ H√¨nh") #
    
    if 'checkpoint_path_input' not in st.session_state: #
        st.session_state.checkpoint_path_input = "YOUR_MODEL_CHECKPOINT.pth" #
    if 'class_indices_path_input' not in st.session_state: #
        st.session_state.class_indices_path_input = "class_indices.json" #
    if 'num_classes_input' not in st.session_state: #
        st.session_state.num_classes_input = 3 #
    
    st.session_state.checkpoint_path_input = st.sidebar.text_input( #
        "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Checkpoint (.pth)", 
        value=st.session_state.checkpoint_path_input, #
        help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn t·ªáp checkpoint c·ªßa m√¥ h√¨nh MedMamba." #
    )
    # st.session_state.class_indices_path_input = st.sidebar.text_input( #
    #     "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Class Indices (.json) (T√πy ch·ªçn)", 
    #     value=st.session_state.class_indices_path_input, #
    #     help="T·ªáp JSON ch·ª©a √°nh x·∫° t·ª´ index sang t√™n l·ªõp." #
    # )
    # st.session_state.num_classes_input = st.sidebar.number_input( #
    #     "S·ªë L∆∞·ª£ng L·ªõp (n·∫øu kh√¥ng c√≥ trong checkpoint)", 
    #     min_value=1, value=st.session_state.num_classes_input, step=1, #
    #     help="S·ªë l·ªõp ƒë·∫ßu ra c·ªßa m√¥ h√¨nh. S·∫Ω ƒë∆∞·ª£c ghi ƒë√® n·∫øu checkpoint ch·ª©a th√¥ng tin n√†y." #
    # )

    if 'model' not in st.session_state: #
        st.session_state.model = None #
        st.session_state.device = None #
        st.session_state.class_indices = None #
        st.session_state.num_classes_loaded = st.session_state.num_classes_input #
        st.session_state.model_loaded_path = "" #
        st.session_state.last_prediction_info = None #
        st.session_state.image_to_display_caption = "" # Th√™m ƒë·ªÉ l∆∞u caption ·∫£nh g·ªëc
        st.session_state.image_to_display_pil = None # Th√™m ƒë·ªÉ l∆∞u ·∫£nh g·ªëc PIL

    if st.sidebar.button("N·∫°p M√¥ H√¨nh", key="load_model_button"): #
        st.session_state.model = None  #
        st.session_state.last_prediction_info = None  #
        st.session_state.image_to_display_pil = None #
        if st.session_state.checkpoint_path_input: #
            model, device, class_indices_from_ckpt, num_classes_final = load_medmamba_model( #
                st.session_state.checkpoint_path_input, 
                st.session_state.num_classes_input
            )
            
            if model and device: #
                st.session_state.model = model #
                st.session_state.device = device #
                st.session_state.num_classes_loaded = num_classes_final #
                st.session_state.model_loaded_path = st.session_state.checkpoint_path_input #

                class_indices_from_file = load_class_indices_from_file(st.session_state.class_indices_path_input) #
                if class_indices_from_file: #
                    st.session_state.class_indices = class_indices_from_file #
                elif class_indices_from_ckpt: #
                    st.session_state.class_indices = class_indices_from_ckpt #
                    st.sidebar.info("ƒê√£ s·ª≠ d·ª•ng class_indices t·ª´ checkpoint.") #
                else: #
                    st.session_state.class_indices = None #
                    st.sidebar.warning("Kh√¥ng t√¨m th·∫•y class_indices. D·ª± ƒëo√°n s·∫Ω ch·ªâ hi·ªÉn th·ªã index c·ªßa l·ªõp.") #
            else: #
                st.session_state.model = None #
                st.session_state.class_indices = None #
        else: #
            st.sidebar.error("Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn checkpoint.") #

    if st.session_state.model is None: #
        st.warning("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c n·∫°p. Vui l√≤ng c·∫•u h√¨nh v√† nh·∫•n 'N·∫°p M√¥ H√¨nh' trong thanh sidebar.") #
        st.stop() #

    st.success(f"M√¥ h√¨nh **{os.path.basename(st.session_state.model_loaded_path)}** ƒë√£ ƒë∆∞·ª£c n·∫°p v√† s·∫µn s√†ng!") #
    st.info(f"S·ªë l·ªõp c·ªßa m√¥ h√¨nh: **{st.session_state.num_classes_loaded}**") #
    if st.session_state.class_indices: #
        st.write("C√°c l·ªõp ƒë∆∞·ª£c ph√°t hi·ªán:") #
        st.json(st.session_state.class_indices, expanded=False) #
    
    img_transform = get_transform() #

    st.markdown("---") #
    st.header("üî¨ Ch·ªçn ·∫¢nh & Xem K·∫øt Qu·∫£ Ph√¢n T√≠ch") #
    
    prediction_mode = st.radio( #
        "Ch·ªçn ngu·ªìn ·∫£nh:", #
        ("T·∫£i ·∫¢nh L√™n", "·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c"), #
        key="prediction_mode_radio",
        horizontal=True
    )

    # X·ª≠ l√Ω vi·ªác ch·ªçn ·∫£nh v√† n√∫t b·∫•m
    if prediction_mode == "T·∫£i ·∫¢nh L√™n": #
        uploaded_file = st.file_uploader( #
            "Ch·ªçn m·ªôt h√¨nh ·∫£nh...", 
            type=["png", "jpg", "jpeg", "bmp"], #
            key="file_uploader",
            on_change=lambda: st.session_state.update(last_prediction_info=None, image_to_display_pil=None) # Reset khi c√≥ file m·ªõi
        )
        if uploaded_file is not None: #
            try:
                st.session_state.image_to_display_pil = Image.open(uploaded_file).convert('RGB') #
                st.session_state.image_to_display_caption = "·∫¢nh ƒê√£ T·∫£i L√™n" #
            except Exception as e: #
                st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh t·∫£i l√™n: {e}") #
                st.session_state.image_to_display_pil = None #

    elif prediction_mode == "·∫¢nh Ng·∫´u Nhi√™n T·ª´ Th∆∞ M·ª•c": #
        if 'test_dir_input' not in st.session_state: #
            st.session_state.test_dir_input = "PATH_TO_YOUR_TEST_IMAGE_FOLDER" #

        st.session_state.test_dir_input = st.text_input( #
            "ƒê∆∞·ªùng d·∫´n ƒë·∫øn Th∆∞ M·ª•c ·∫¢nh Test", 
            value=st.session_state.test_dir_input, #
            help="Cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c ·∫£nh ƒë·ªÉ ch·ªçn ng·∫´u nhi√™n." #
        )

        if st.button("L·∫•y ·∫¢nh Ng·∫´u Nhi√™n, D·ª± ƒêo√°n & Hi·ªán Grad-CAM", key="random_predict_gradcam_button"):
            st.session_state.last_prediction_info = None # Reset d·ª± ƒëo√°n c≈©
            st.session_state.image_to_display_pil = None
            if not os.path.isdir(st.session_state.test_dir_input): #
                st.error(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {st.session_state.test_dir_input}") #
            else: #
                image_files = [] #
                for root, _, files in os.walk(st.session_state.test_dir_input): #
                    for file in files: #
                        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')): #
                            image_files.append(os.path.join(root, file)) #
                
                if not image_files: #
                    st.warning(f"Kh√¥ng t√¨m th·∫•y t·ªáp ·∫£nh n√†o trong th∆∞ m·ª•c: {st.session_state.test_dir_input}") #
                else: #
                    random_image_path = random.choice(image_files) #
                    try:
                        random_pil_image = Image.open(random_image_path).convert('RGB') #
                        st.session_state.image_to_display_pil = random_pil_image #
                        st.session_state.image_to_display_caption = f"·∫¢nh Ng·∫´u Nhi√™n: {os.path.basename(random_image_path)}" #
                        
                        # Th·ª±c hi·ªán d·ª± ƒëo√°n ngay sau khi l·∫•y ·∫£nh
                        with st.spinner("ƒêang d·ª± ƒëo√°n..."): #
                            class_name, confidence, class_idx = predict( #
                                st.session_state.model, #
                                st.session_state.device, #
                                st.session_state.image_to_display_pil, #
                                img_transform, #
                                st.session_state.class_indices #
                            )
                        st.session_state.last_prediction_info = { #
                            "image_pil": st.session_state.image_to_display_pil, #
                            "image_caption": st.session_state.image_to_display_caption, #
                            "class_name": class_name, #
                            "confidence": confidence, #
                            "predicted_idx": class_idx #
                        }
                    except Exception as e: #
                        st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh {random_image_path}: {e}") #
                        st.session_state.image_to_display_pil = None #
    
    # N√∫t "Th·ª±c Hi·ªán D·ª± ƒêo√°n" cho ·∫£nh t·∫£i l√™n
    if prediction_mode == "T·∫£i ·∫¢nh L√™n" and st.session_state.image_to_display_pil: #
        if st.button("Th·ª±c Hi·ªán D·ª± ƒêo√°n & Hi·ªán Grad-CAM", key="upload_predict_gradcam_button"):
            st.session_state.last_prediction_info = None # Reset d·ª± ƒëo√°n c≈©
            with st.spinner("ƒêang d·ª± ƒëo√°n..."): #
                class_name, confidence, class_idx = predict( #
                    st.session_state.model, #
                    st.session_state.device, #
                    st.session_state.image_to_display_pil, #
                    img_transform, #
                    st.session_state.class_indices #
                )
            st.session_state.last_prediction_info = { #
                "image_pil": st.session_state.image_to_display_pil, #
                "image_caption": st.session_state.image_to_display_caption, #
                "class_name": class_name, #
                "confidence": confidence, #
                "predicted_idx": class_idx #
            }

    # Hi·ªÉn th·ªã ·∫£nh g·ªëc (n·∫øu c√≥)
    if st.session_state.get('image_to_display_pil') is not None:
        st.image(st.session_state.image_to_display_pil, caption=st.session_state.get('image_to_display_caption',"·∫¢nh ƒë√£ ch·ªçn"), width=300) #
    elif prediction_mode == "T·∫£i ·∫¢nh L√™n":
        st.info("Vui l√≤ng t·∫£i ·∫£nh l√™n.")
    
    # --- Ph·∫ßn hi·ªÉn th·ªã k·∫øt qu·∫£ v√† Grad-CAM ---
    last_prediction_info = st.session_state.get('last_prediction_info', None) #

    if last_prediction_info and last_prediction_info.get("image_pil") is not None: #
        st.markdown("---") #
        
        # Th√¥ng tin d·ª± ƒëo√°n hi·ªÉn th·ªã ·ªü tr√™n
        st.subheader("K·∫øt Qu·∫£ D·ª± ƒêo√°n:") #
        target_idx_int = -1
        try:
            target_idx_int = int(target_category_input_gradcam)
        except:
            pass

        if st.session_state.class_indices and str(target_idx_int) in st.session_state.class_indices:
            target_class_name = st.session_state.class_indices[str(target_idx_int)]
            st.markdown(f"**T√™n L·ªõp M·ª•c Ti√™u:** `{target_class_name}`")
        elif target_idx_int >= 0:
            st.markdown(f"**T√™n L·ªõp M·ª•c Ti√™u:** _(Kh√¥ng x√°c ƒë·ªãnh - kh√¥ng c√≥ √°nh x·∫° t√™n l·ªõp cho index n√†y)_")
        st.markdown(f"**L·ªõp D·ª± ƒêo√°n:** `{last_prediction_info['class_name']}` (Index: {last_prediction_info['predicted_idx']})") #
        st.markdown(f"**ƒê·ªô Tin C·∫≠y:** `{last_prediction_info['confidence']:.4f}`") #

        st.subheader("üî• Grad-CAM Visualization") #
        pil_image_for_gradcam = last_prediction_info["image_pil"] #
        predicted_idx_for_gradcam = last_prediction_info["predicted_idx"] #
        predicted_class_name_display_gradcam = last_prediction_info["class_name"] #
        
        # S·ª≠ d·ª•ng id c·ªßa ·∫£nh l√†m ph·∫ßn c·ªßa key ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh duy nh·∫•t khi ·∫£nh thay ƒë·ªïi
        target_category_key = f"target_category_gradcam_input_for_{id(pil_image_for_gradcam)}_{predicted_idx_for_gradcam}" #
        
        # L·∫•y gi√° tr·ªã hi·ªán t·∫°i t·ª´ session_state ho·∫∑c d√πng gi√° tr·ªã m·∫∑c ƒë·ªãnh
        current_input_value_for_gradcam = st.session_state.get(target_category_key, str(predicted_idx_for_gradcam)) #

        target_category_input_gradcam = st.text_input( #
            f"Index L·ªõp M·ª•c Ti√™u cho Grad-CAM (m·∫∑c ƒë·ªãnh: l·ªõp d·ª± ƒëo√°n - '{predicted_class_name_display_gradcam}' (Index: {predicted_idx_for_gradcam}))", #
            key=target_category_key, #
            value=current_input_value_for_gradcam # 
        )
        
        target_category_for_gradcam = predicted_idx_for_gradcam #
        if target_category_input_gradcam.strip(): #
            try:
                target_category_for_gradcam = int(target_category_input_gradcam) #
            except ValueError: #
                st.warning(f"Gi√° tr·ªã '{target_category_input_gradcam}' kh√¥ng h·ª£p l·ªá cho Target Category. S·ª≠ d·ª•ng index l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n ({predicted_idx_for_gradcam}).") #
        
        num_classes_loaded = st.session_state.num_classes_loaded #
        if not (0 <= target_category_for_gradcam < num_classes_loaded): #
            st.error(f"Target Category Index ({target_category_for_gradcam}) n·∫±m ngo√†i kho·∫£ng h·ª£p l·ªá [0, {num_classes_loaded-1}]. Vui l√≤ng ch·ªçn m·ªôt index h·ª£p l·ªá.") #
        else: #
            with st.spinner("ƒêang t·∫°o Grad-CAM..."): #
                original_img_display, cam_image = generate_gradcam_image( #
                    st.session_state.model, #
                    st.session_state.device, #
                    pil_image_for_gradcam, #
                    target_category_for_gradcam, #
                    st.session_state.class_indices, #
                    img_size=224
                )

            if original_img_display is not None and cam_image is not None: #
                target_gradcam_class_name_display = str(target_category_for_gradcam) #
                if st.session_state.class_indices: #
                    target_gradcam_class_name_display = st.session_state.class_indices.get(str(target_category_for_gradcam), str(target_category_for_gradcam)) #
                
                # Hi·ªÉn th·ªã ·∫£nh g·ªëc v√† Grad-CAM c·∫°nh nhau
                col_img1, col_img2 = st.columns(2)
                with col_img1:
                    st.image(original_img_display, caption=last_prediction_info.get("image_caption", "·∫¢nh ƒë√£ x·ª≠ l√Ω"), use_container_width=True) #
                with col_img2:
                    st.image(cam_image, caption=f"Grad-CAM cho l·ªõp: {target_gradcam_class_name_display}", use_container_width=True) #
            # L·ªói ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω b√™n trong generate_gradcam_image
    
    st.sidebar.markdown("---") #
    st.sidebar.markdown("ƒê∆∞·ª£c h·ªó tr·ª£ b·ªüi ƒê·ªëi t√°c L·∫≠p tr√¨nh Gemini") #

if __name__ == '__main__': #
    main_app() #